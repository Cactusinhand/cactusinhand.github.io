[{"title":"如何向 Git 社区提交代码(2)","path":"/posts/23bf24d1.html","content":"背景 第一次向 Git 社区提交代码起源于 Gitee 的一个需求。Gitee 创建新仓库有多种方式，其中一种是根据用户提供的仓库 URL 导入新仓库，Gitee 首先会对用户提供的 URL 进行校验，只有合格的仓库地址才会生成新仓库。但是有种情况比较特别，若用户确实提供了一个合法的 Git 仓库地址，但是这个仓库不是完整的，常见的情况就是浅仓库(shallow repo)，这类仓库缺乏足够的历史提交信息，因此会带来一些问题。为了避免这种情况，在服务端就需要对用户导入的仓库进行特别处理。在服务端，导入仓库的动作本质上就是执行 git clone --mirror 命令，那么有没有可能在执行这个克隆命令的过程中就对仓库进行判断呢？如果能，这将避免克隆完整个仓库再进行判断仓库是否为浅仓库，这样无疑更有效。于是我开始研究 Git 源码，琢磨如何给 git-clone 命令赋予一项新的能力。 按照前面的方法向 Git 社区提交了第一版代码：v1 很快收到 Junio C Hamano 反馈，主要问题有： commit 信息中说明不清，英文语法错误： 123456789101112131415161718192021222324&gt; This patch add a new option that reject to clone a shallow repository.A canonical form of our log message starts by explaining the need,and then presents the solution at the end.一条规范的 commit 信息格式应该是在开始就解释更改需求，然后在结尾提供解决方案。&gt; Clients don&#x27;t know it&#x27;s a shallow repository until they download it&gt; locally, in some scenariors, clients just don&#x27;t want to clone this kind&quot;scenarios&quot;. &quot;in some scenarios&quot; would have to be clarified a bitmore to justify why it is a good idea to have such a feature.这里的需求场景描述地不够有说服力。&gt; of repository, and want to exit the process immediately without creating&gt; any unnecessary files.&quot;clients don&#x27;t know it&#x27;s a shallow repository until they download&quot;leading to &quot;so let&#x27;s reject immediately upon finding out that theyare shallow&quot; does make sense as a flow of thought, though.这里表述不够清晰，Junio 顺便提供了他的建议&gt; +--no-shallow::&gt; +\tDon&#x27;t clone a shallow source repository. In some scenariors, clients&quot;scenarios&quot; (no &#x27;r&#x27;). 新增选项 --no-shallow 不对，应该考虑到布尔类选项存在反选情况，即 --no-no-shallow ，因此不应该这么写，建议改为 --reject-shallow， 它的反选即为 --no-reject-shallow，这样语义上也更符合直觉： 123456789101112131415161718192021222324252627282930313233343536373839&gt; diff --git a/builtin/clone.c b/builtin/clone.c&gt; @@ -90,6 +91,7 @@ static struct option builtin_clone_options[] = &#123;&gt; OPT__VERBOSITY(&amp;option_verbosity),&gt; OPT_BOOL(0, &quot;progress&quot;, &amp;option_progress,&gt; N_(&quot;force progress reporting&quot;)),&gt; +\tOPT_BOOL(0, &quot;no-shallow&quot;, &amp;option_no_shallow, N_(&quot;don&#x27;t clone shallow repository&quot;)),&gt; OPT_BOOL(&#x27;n&#x27;, &quot;no-checkout&quot;, &amp;option_no_checkout,&gt; N_(&quot;don&#x27;t create a checkout&quot;)),&gt; OPT_BOOL(0, &quot;bare&quot;, &amp;option_bare, N_(&quot;create a bare repository&quot;)),It is a bad idea to give a name that begins with &quot;no-&quot; to an optionwhose default can be tweaked by a configuration variable [*]. Ifthe configuration is named &quot;rejectshallow&quot;, perhaps it is better tocall it &quot;--reject-shallow&quot; instead.This is because configured default must be overridable from thecommand line. I.e. even if you have in your ~/.gitconfig this: [clone] rejectshallow = trueyou should be able to say &quot;allow it only this time&quot;, with $ git clone --no-reject-shallow http://github.com/git/git/ gitand you do not want to have to say &quot;--no-no-shallow&quot;, which soundsjust silly.\tSide note. it is a bad idea in general, even if the option\tdoes not have corresponding configuration variable. The\texisting &quot;no-checkout&quot; is a historical accident that\thappened long time ago and cannot be removed due to\tcompatibility. Let&#x27;s not introduce a new option that\tfollows such a bad pattern.\tJunio 进一步解释：现存的选项 `no-checkout` 是一个很久之前的历史错误，\t由于兼容性，已经无法移除这个错误了，现在新的选项不应该按照这种模式命名。\tP.S. 刚好我就是按照`no-checkout`选项的模式创造出`no-shllow`选项的-:) 更重要的是，命令行优先于配置，即命令行选项要能够覆盖配置文件选项。当配置文件从全局上不允许克隆 shllow 仓库时，而用户想要允许单次克隆 shallow 仓库时，自然地，他会使用 --no-shallow 选项的反选项 --no-no-shallow 来覆盖掉配置中的选项 。但这样 --no-no-shallow 听来去就很傻。 由于 Git 存在多种传输协议，目前的修改只是解决了本地克隆问题，因此仍需改进： 123456789101112131415161718192021222324252627282930313233343536&gt; @@ -963,6 +968,7 @@ static int path_exists(const char *path)&gt; int cmd_clone(int argc, const char **argv, const char *prefix)&gt; &#123;&gt; int is_bundle = 0, is_local;&gt; +\tint is_shallow = 0;&gt; const char *repo_name, *repo, *work_tree, *git_dir;&gt; char *path, *dir, *display_repo = NULL;&gt; int dest_exists, real_dest_exists = 0;&gt; @@ -1215,6 +1221,7 @@ int cmd_clone(int argc, const char **argv, const char *prefix)&gt; if (filter_options.choice)&gt; warning(_(&quot;--filter is ignored in local clones; use file:// instead.&quot;));&gt; if (!access(mkpath(&quot;%s/shallow&quot;, path), F_OK)) &#123;&gt; + is_shallow = 1;&gt; if (option_local &gt; 0)&gt; warning(_(&quot;source repository is shallow, ignoring --local&quot;));&gt; is_local = 0;This change is to the local clone codepath. Cloning over the wirewould not go through this part. And throughout the patch, this isthe only place that sets is_shallow to 1.Also let&#x27;s note that this is after we called parse_options(), so thevalue of option_no_shallow is known at this point.So, this patch does not even *need* to introduce a new &quot;is_shallow&quot;variable at all. It only needs to add if (option_no_shallow) die(...);instead of adding &quot;is_shallow = 1&quot; to the above hunk.I somehow think that this is only half a feature---wouldn&#x27;t it bemore useful if we also rejected a non-local clone from a shallowrepository? 测试代码中的问题： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374And for that ...&gt; diff --git a/t/t5606-clone-options.sh b/t/t5606-clone-options.sh&gt; index 7f082fb23b6a..9d310dbb158a 100755&gt; --- a/t/t5606-clone-options.sh&gt; +++ b/t/t5606-clone-options.sh&gt; @@ -42,6 +42,13 @@ test_expect_success &#x27;disallows --bare with --separate-git-dir&#x27; &#x27;&gt; &gt; &#x27;&gt; &gt; +test_expect_success &#x27;reject clone shallow repository&#x27; &#x27;&gt; +\tgit clone --depth=1 --no-local parent shallow-repo &amp;&amp;&gt; +\ttest_must_fail git clone --no-shallow shallow-repo out 2&gt;err &amp;&amp;&gt; +\ttest_i18ngrep -e &quot;source repository is shallow, reject to clone.&quot; err&gt; +&gt; +&#x27;&gt; +... in addition to the test for a local clone above, you&#x27;d also wantto test a non-local clone, perhaps like so:test_expect_success &#x27;reject clone shallow repository&#x27; &#x27;\trm -fr shallow-repo &amp;&amp;\tgit clone --depth=1 --no-local parent shallow-repo &amp;&amp;\ttest_must_fail git clone --no-shallow --no-local shallow-repo out 2&gt;err &amp;&amp;\ttest_i18ngrep -e &quot;source repository is shallow, reject to clone.&quot; err&#x27;Ditto for the other test script.Also, you would want to make sure that the command line overridesthe configured default. I.e.\tgit -c clone.rejectshallow=false clone --reject-shallowshould refuse to clone from a shallow one, while there should be away to countermand a configured &quot;I always refuse to clone from ashallow repository&quot; with &quot;but let&#x27;s allow it only this time&quot;, i.e.\tgit -c clone.rejectshallow=true clone --no-reject-shallowor something along the line.&gt; diff --git a/t/t5611-clone-config.sh b/t/t5611-clone-config.sh&gt; index 8e0fd398236b..3aab86ad4def 100755&gt; --- a/t/t5611-clone-config.sh&gt; +++ b/t/t5611-clone-config.sh&gt; @@ -92,6 +92,13 @@ test_expect_success &#x27;clone -c remote.&lt;remote&gt;.fetch=&lt;refspec&gt; --origin=&lt;name&gt;&#x27; &#x27;&gt; test_cmp expect actual&gt; &#x27;&gt; &gt; +test_expect_success &#x27;clone -c clone.rejectshallow&#x27; &#x27;&gt; +\trm -rf child &amp;&amp;&gt; +\tgit clone --depth=1 --no-local . child &amp;&amp;&gt; +\ttest_must_fail git clone -c clone.rejectshallow child out 2&gt;err &amp;&amp;This is not quite right, even though it may happen to work. The&quot;clone.rejectshallow&quot; variable is a configuration about what shouldhappen when creating a new repository by cloning, so letting &quot;gitclone -c var[=val]&quot; to set the variable _in_ the resulting repositorywould not make much sense. Even if the clone succeeded, nobody wouldlook at that particular configuration variable that is set in theresulting repository.I think it would communicate to the readers better what we aretrying to do, if we write\ttest_must_fail git -c clone.rejectshallow=true clone child outinstead.Thanks. 通过测试代码 Junio 指出： clone.rejectshallow 配置和命令行选项 --reject-shallow 存在逻辑上的交叉重叠问题，因此测试时应该体现出这一点。 以上就是我第一次提交的代码，没想到能很快收到那么多宝贵的检视建议。但是，这只是开始，后面还有更多的检视回合，收到了更加细致的检视意见。 比如 Johannes Schindelin 给了一些意见： 123456789101112131415161718192021我觉得这个补丁大部分都很好，但我还有一点点改进建议I like most of the patch, and will only point out a couple of things thatI think can be improved even further.&gt; diff --git a/Documentation/git-clone.txt b/Documentation/git-clone.txt&gt; index 02d9c19cec75..0adc98fa7eee 100644&gt; --- a/Documentation/git-clone.txt&gt; +++ b/Documentation/git-clone.txt&gt; @@ -149,6 +149,11 @@ objects from the source repository into a pack in t=he cloned repository.&gt; --no-checkout::&gt; No checkout of HEAD is performed after the clone is complete.&gt;&gt; +--[no-]reject-shallow::&gt; +\tFail if the source repository is a shallow repository.&gt; +\tThe &#x27;clone.rejectShallow&#x27; configuration variable can be used to&gt; +\tgive the default.使用 `to specify the default` 说起来更顺口一些I am not a native speaker, either, but I believe that it would &quot;roll offthe tongue&quot; a bit better to say &quot;to specify the default&quot;. 变量命名问题： 12345678910111213141516171819202122232425262728293031323334353637383940&gt; diff --git a/builtin/clone.c b/builtin/clone.c&gt; index 51e844a2de0a..eeddd68a51f4 100644&gt; --- a/builtin/clone.c&gt; +++ b/builtin/clone.c&gt; @@ -50,6 +50,8 @@ static int option_no_checkout, option_bare, option_mir=ror, option_single_branch&gt; static int option_local =3D -1, option_no_hardlinks, option_shared;&gt; static int option_no_tags;&gt; static int option_shallow_submodules;&gt; +static int option_shallow = -1; /* unspecified */&gt; +static int config_shallow = -1; /* unspecified */I would much prefer those variable names to include an indicator that thisis about _rejecting_ shallow clones. I.e. `option_reject_shallow`.Also, I think that we can do with just a single `option_reject_shallow`(we do not even need that `reject_shallow` variable in `cmd_clone()`):- in `git_clone_config()`, only override it if it is still unspecified:\tif (!strcmp(k, &quot;clone.rejectshallow&quot;) &amp;&amp; option_reject_shallow &lt; 0) option_reject_shallow =3D git_config_bool(k,v);- in `cmd_clone()`, test for a _positive_ value:\tif (option_reject_shallow &gt; 0) die(_(&quot;source repository is shallow, reject to clone.&quot;)); and\tif (option_reject_shallow &gt; 0) transport_set_option(transport, TRANS_OPT_REJECT_SHALLOW, &quot;1&quot;);One thing to note (in the commit message, would be my preference) is that`cmd_clone()` is _particular_ in that it runs `git_config()` _twice_. Oncebefore the command-line options are parsed, and once after the new Gitrepository has been initialized. Note that my suggestion still works withthat: if either the original config, or the new config set`clone.rejectShallow`, it is picked up correctly, with the latteroverriding the former if both configs want to set it. 使用 option_reject_shallow 比 config_shallow 更好一些，它能更直接地表明这个选项是要拒绝 shallow clone 的。同时他提醒，在 cmd_clone()函数中 git_config 会被调用两次，使用 option_reject_shallow 能避免在 cmd_clone 中使用 reject_shallow 。 P.S. 划线这段话是错误的，见 Johannes 本人回复：Johannes’reply，以及 Junio 的回复：Junio’s reply。最后用了两个变量: option_reject_shallow，config_reject_shallow，在 cmd_clone() 中它们共同决定另一个变量：reject_shallow。 后面同样变量命名： 12345678910111213141516171819&gt; diff --git a/fetch-pack.c b/fetch-pack.c&gt; index fb04a76ca263..34d0c2896e2e 100644&gt; --- a/fetch-pack.c&gt; +++ b/fetch-pack.c&gt; @@ -1129,9 +1129,11 @@ static struct ref *do_fetch_pack(struct fetch_pac=k_args *args,&gt; if (args-&gt;deepen)&gt; setup_alternate_shallow(&amp;shallow_lock, &amp;alternate_shallow_file,&gt; NULL);&gt; -\telse if (si-&gt;nr_ours || si-&gt;nr_theirs)&gt; +\telse if (si-&gt;nr_ours || si-&gt;nr_theirs) &#123;&gt; + if (args-&gt;remote_shallow)Even as a non-casual reader, this name `remote_shallow` leads me to assumeincorrect things. This option is not about wanting a remote shallowrepository, it is about rejecting a remote shallow repository.用 `reject_shallow` 代替 `remote_shllow`Please name this attribute `reject_shallow` instead of `remote_shallow`.That will prevent future puzzlement. Johannes 还对测试用例提出了一些检视意见，篇幅有限，这里省略。 在最后几个回合，Junio 又给出了很多有意义的检视意见： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&gt; In some scenarios, users may want more history than the repository&gt; offered for cloning, which happens to be a shallow repository, can&gt; give them. But because users don&#x27;t know it is a shallow repository&gt; until they download it to local, users should have the option to&#x27;should&#x27; 在这里感觉语气太重了I find the &quot;should&quot; too strong, but let&#x27;s keep reading.&gt; refuse to clone this kind of repository, and may want to exit the&gt; process immediately without creating any unnecessary files.确认是语气重了。同时存在冗余。Yes, that is too strong and also redundant.&gt; Althought there is an option &#x27;--depth=x&#x27; for users to decide how&gt; deep history they can fetch, but as the unshallow cloning&#x27;s depth句子若以 &#x27;although&#x27; 开头，则后面不应该用 `but`做转折。&quot;Although&quot;; if you begin with &quot;although&quot;, you shouldn&#x27;t write &quot;but&quot;.&gt; is INFINITY, we can&#x27;t know exactly the minimun &#x27;x&#x27; value that can&gt; satisfy the minimum integrity,&gt; so we can&#x27;t pass &#x27;x&#x27; value to --depth,&gt; and expect this can obtain a complete history of a repository.If the argument were &quot;we might start with depth x, and the sourcemay be deep enough to give us x right now, but we may want to deepenmore than they can offer, and such a user would want to be able tosay &#x27;I want depth=x now, but make sure they are not shallow&#x27;&quot;, Iwould understand it, but I do not see where the &quot;minimum integrity&quot;comes from---there doesn&#x27;t appear to be anything related tointegrity here.&gt; In other scenarios, if we have an API that allow us to import external&quot;allows&quot;&gt; repository, and then perform various operations on the repo.&gt; But if the imported is a shallow one(which is actually possible), it&gt; will affect the subsequent operations. So we can choose to refuse to&gt; clone, and let&#x27;s just import a normal repository.建议丢掉这一整段，因为它跟前面讲的场景差不多，并没有提供新信息。I&#x27;d suggest dropping this entire paragraph. That is not any newscenario at all. API or not, you essentially just said &quot;you can dovarious things on your clone once you have it, but some things youmay want to do you would want a full history&quot;. That is what youstarted the whole discussion above and does not add any newinformation.&gt; @@ -858,6 +861,9 @@ static int git_clone_config(const char *k, const char *v, void *cb)&gt; free(remote_name);&gt; remote_name = xstrdup(v);&gt; &#125;&gt; +\tif (!strcmp(k, &quot;clone.rejectshallow&quot;) &amp;&amp; option_reject_shallow &lt; 0)&gt; + option_reject_shallow = git_config_bool(k, v);Does this &quot;single variable is enough&quot; really work?Imagine that the first time around we&#x27;d read from $HOME/.gitconfigthat says true (flips the variable from &quot;unspecified&quot;). Furtherimagine that we are running &quot;git clone -c config.rejectShallow=no&quot;to countermand the global config. We call write_config() to writethe extra configuration value out, and then call git_config() toread from the repository configuration again.Because of the value taken from $HOME/.gitconfig, however, theattempt to override is silently ignored, isn&#x27;t it?Other than that, the changes to the code from the previous roundlooked sensible.虽然比上一版的更新好了很多，但Junio并没有放弃任何可能的问题，仍对config配置和option配置有疑问，他的顾虑是正确的，这为下一版的更新提供了正确的思路。 这就是我第一次向 Git 社区提交代码的情况：问题多多，反馈多多。各种严谨细致又有启发性的检视意见让我感受到了 Git 社区的技术氛围。这个过程中让我不断思考如何让代码写得更好：更有逻辑，更简洁，更严谨，而不仅仅是实现功能。 这个经验让我想到，在英语中有个两个单词可以很贴切的形容他们对待代码的态度：polish，cooking。 polish 动词意为润色，修改，抛光，打磨。用在代码上， commit 信息上，甚至写文档上，意味着这些过程是不断改进，不断变得更好。 cooking 意为烹饪，比喻写代码就像烹饪，所谓心急吃不了热豆腐，即使做简单的菜都需要耐心，细心。 回到主题，前面的每次修改，直接强推到原来的PR中即可， GitGitGadget 会自动将每次的更新转换为不同的版本再提交到上游社区。那如何确定提交的版本是最终版本呢？前面提到过 Git 的几个主要分支，当我提交到第十版后，很快就被合入到 seen分支，意味着被初步接受，然后又马上进入 next 分支，意味着各项测试也没问题，然后又马上进入 master 分支。特别地，这个过程会有 状态更新 提醒， Git 社区有个 What’s cooking in git.git 栏目，是维护者 Junio 用来管理各种提交的状态更新的，它会表明目前社区正在 cooking 哪些人的哪些代码(patch)，以及各个代码的目前状态。当你的代码在 What’s cooking in git.git 中进入 Graduated to 'master' 或者 Will merge to 'master'，那就表明马上会合入主线啦。","tags":["Git","Workflow"],"categories":["Git"]},{"title":"如何向 Git 社区提交代码","path":"/posts/d699447b.html","content":"前言 作为目前最流行的开源分布式版本控制系统，Git 的诞生超过17年，但目前仍然具有非常活跃的开发者社区，远超出一般开源软件的生命周期，其代码贡献者也已经超过 1.5K，并且仍源源不断有新增贡献者，这使得 Git 能够持续不断地有各种更新、功能优化等等。 但是要想参与到这个大型的国际化的开源社区中来并成为源码贡献者，对于国内大部分开发者来说并不是那么容易。 在 Gitee 架构团队中，我有机会深入探究 Git的底层原理，以及 Git 的一些应用，这个过程中我也成为了 Git 社区的贡献者。截至目前，我向 Git 社区提交了 4 次代码。现在，作为贡献者中的一员，我很乐意分享这个过程，以便帮助更多人有机会参与到像 Git 这样的大型开源社区中来。 这个系列将从 Git 社区贡献者的角度，向广大开发者分享我如何向 Git 官方社区提交代码，以及从提交代码到最终合并代码的整个过程。 背景 如果你在使用 Git 时发现了 bug，或者觉得某些命令没有你想要的功能，或者你发现它的帮助文档描述不够清晰让你感到迷惑，你完全可以自己修改 Git 源码，从而实现自己的预期功能。 获取源码 首先从 Git 在 Github 镜像仓 上 fork 出一个自己的仓库，然后克隆到本地： 1234$ git clone https://github.com/myfork/git mygit$ cd mygit# 添加上游远程仓库，便于更新最新代码$ git remote add upstream https://github.com/git/git 编译源码 确保在未作任何修改之前，代码不缺少任何编译依赖，能够正常编译。 123# 切出一个自己的主题分支$ git checkout -b myown-topic origin/master$ make DEVELOPER=1 topic 是个人主题分支，所谓主题就是自己要修改什么那就是什么主题。 编写代码 其实编写代码的过程就是一个模仿的过程，先观察别人是怎么写的，再模仿写即可。比如，观察别人是如何定义变量，在哪里定义，如何处理缩进，如何定义函数等等，按照同样的风格进行模仿大致是不会出错的。如果想看详细的编码规范，可参考 Git 代码编写规范 测试代码 测试代码都在 t/ 目录下，请阅读 t/README 文档，然后编写测试用例。 运行单项测试： 12$ make DEVELOPER=1$ cd t/ &amp;&amp; prove t9999-psuh-tutorial.sh 或者运行全部测试，以确保自己的修改没有影响别的代码运行： 12$ cd t/$ prove -j$(nproc) --shuffle t[0-9]*.sh 文档更新 如果修改是新增某个特性，或者增加某个选项配置等，都需要补充文档，使用说明，manpage等。 Linux环境中需要安装 asciidoc 工具，来支持文档 123$ sudo apt-get install asciidoc$ make all doc$ make check-docs 对待文档需要跟对待代码一样，因为它们同样重要。和编写代码一样，需要遵循已有文档的风格，详细风格指导文档请参考可参考 Git 代码编写规范中的 Writing Documentation 章节。 编写 commit 编写 commit 信息也是很重要的一步，这个后续系列文章我会专门说明这一点。 创建 commit 的原则，首先是对逻辑上不同的更改进行不同的提交(make separate commits for logically separate changes)，也就是保持每个commit尽量独立且是最小更改。 每条 commit 需要带上签名，使用 git commit -s ，-s/--signoff 选项会在 commit 尾部加上 Signed-off-by：签名信息。 编写commit message 需要遵循一定规范，如下图： 对于commit message, 官方主要维护者说：A canonical form of our log message starts by explaining the need, and then presents the solution at the end.(一个标准的格式的 commit message 应该在开头描述需求，在结尾展示解决方案。) commit head 部分不超过 50 个字符 commit body 部分不超过 76 个字符 向社区提交代码 首先有以下几点需要注意： Git 仓库主要有 5 个分支，master, maint, seen, next, todo。其中： seen 是观察分支，向官方提交一般补丁，初步被接受后还需先进入观察期，即合并到seen 分支，此时还要继续接受别人的代码检视，可能会继续修改。 next 是预备分支，当 seen 上准备好了后，进入 next 分支，接受更多更广泛的测试，保证新补丁不会引发其它 issue。 master 是稳定分支， 在 next 分支上的补丁通过各种测试后，就可以进入稳定分支。 maint 是维护分支，bugfix 一般在这个分支上进行(也可以在 master 分支上进行) 向社区发送邮件至少需要以下邮件地址： 主送官方邮件列表(必须)： git@vger.kernel.org。 抄送代码相关人。比如你的补丁修改了某个文件的某行代码，通过 git-blame 知道这行代码之前的修改者，那么最好也要抄送给这个人，因为他应该比你更熟悉这行代码。 抄送现在主要维护者: gitster@pobox.com Git 社区交流都是用纯文本邮件方式，邮件回复有很多种方式，常见的有 top-posting, bottom-posting, interleaved-style(也叫inline-style)。邮件回复方式详情见 Posting_style Wiki Git 官方社区推荐用 inline-style 回复邮件。 向官方提交代码的方式主要有两种: 一. 通过 Git 命令行： git format-patch 制作补丁包； git send-email 发送邮件到官方社区。 二. 通过 GitGitGadget： 使用Github的PR工作流，向 GitGitGadget 的 Github 仓库 提交 PR； 找人邀请自己，让别人在 PR 评论区发送 /allow(仅针对第一次提交PR的用户)； Github CI 通过后，发送 /submit 触发脚本，自动发送格式化的邮件到官方社区。 通过命令发送邮件向社区提交代码的方式遵循的是比较古老的 mailing list(邮件列表)工作流程，对于现在习惯了直接在网页上提交 PR/MR 的用户来说，邮件列表的方式比较复杂，不建议使用这种方式。但是如果想了解的话，可以参考如下链接：Submit Your Patch GitGitGadget 相当于一套自动化程序，实现了 Github PR 工作流，使所有人能够直接在 Github 上通过提交 PR 的方式向 Git 官方提交代码，这极大的简化了原来的 mailing list工作流。所有这里推荐使用这种方式进行提交代码。 如何在 Github 上提交 PR 大部分人应该都会，所有这里就不展开讲了。对于第一次向 Git 仓库提交代码的情况，这里简单说明一下： 当在本地仓库按照前面的方式编写好 commit 后，push 到自己 fork 的仓库后，回到 gitgitgadget/git 仓库，可以看到： 只需要点击绿色按钮，就可以创建 PR 了。 GitGitGadget 能够检测到用户是第一次提交 PR ，所以 gitgitgadget bot 会自动在 PR 下面发送评论，提示用户该如何操作。这里最重要的一点就是用户(你)需要找一个已经向 Git 成功提交过 PR 的人在你的 PR 评论区发送 /allow 指令，这样你才被正真允许提交 PR。 如果一切顺利，这时候你只需要在 PR 评论区发送 /submit 指令，GitGitGadget 程序会自动将你的 PR 转化为 Git 社区能够接受的格式，并发送到 Git 邮件列表 中。 提交成功！ /submit 指令发送成功后，第一次向 Git 社区提交代码就成功啦！但是，这只是成功的第一步，后续的代码检视，以及你对检视意见的回应才是重点。这将在下一篇文章中介绍。","tags":["Git","Workflow"],"categories":["Git"]},{"title":"GitOps: 一种 DevOps 的最佳实践","path":"/posts/f8df64f6.html","content":"本文转载于：https://icloudnative.io/posts/what-is-gitops/ 作者: 米开朗基杨 GitOps 这个概念最早是由 Kubernetes 管理公司 Weaveworks 公司在 2017 年提出的，如今已经过去了 5 个年头，想必大家对这个概念早有耳闻，但你可能并不知道它到底是什么，它和 DevOps 到底是啥关系，本文就来帮大家一一解惑。 基础设施即代码 在理解 GitOps 之前，我们需要先理解什么是基础设施即代码。 基础设施即代码（Infrastructure as Code, IaC），顾名思义，表示使用代码（而非手动流程）来定义基础设施，研发人员可以像对待应用软件一样对待基础设施，例如： 可以创建包含基础架构规范的声明式配置文件，从而便于编辑和分发配置。 可以确保每次配置的环境都完全相同。 可以进行版本控制，所有的变更都会被记录下来，方便溯源。 可以将基础设施划分为若干个模块化组件，并通过自动化以不同的方式进行组合。 当然，广义上的 IaC 不仅仅只关于基础设施，还包含了网络、安全、配置等等，所以广义上的 IaC 又叫 X as Code。 比如你想在 AWS 中创建服务器，配置网络，部署 Kubernetes 集群以及各种工作负载，你只需要定义好 Terraform 或 Ansible 的声明式配置，以及 Kubernetes 的配置清单即可，免去一切繁杂的手动操作。 GitOps 是什么 GitOps = IaC + Git + CI/CD，即基于 IaC 的版本化 CI/CD。它的核心是使用 Git 仓库来管理基础设施和应用的配置，并且以 Git 仓库作为基础设施和应用的单一事实来源，你从其他地方修改配置（比如手动改线上配置）一概不予通过。 Git 仓库中的声明式配置描述了目标环境当前所需基础设施的期望状态，借助于 GitOps，如果集群的实际状态与 Git 仓库中定义的期望状态不匹配，Kubernetes reconcilers 会根据期望状态来调整当前的状态，最终使实际状态符合期望状态。 另一方面，现代应用的开发更多关注的是迭代速度和规模，拥有成熟 DevOps 文化的组织每天可以将代码部署到生成环境中数百次，DevOps 团队可以通过版本控制、代码审查以及自动测试和部署的 CI/CD 流水线等最佳实践来实现这一目标，这就是 GitOps 干的事情。 GitOps vs DevOps 从广义上来看，GitOps 与 DevOps 并不冲突，GitOps 是一种技术手段，而 DevOps 是一种文化。GitOps 是一种实现持续交付（Continuous Delivery）、持续部署（Continuous Deployment）和基础设施即代码（IaC）的工具和框架，它是支持 DevOps 文化的。 从狭义上来看，GitOps 与 DevOps 有以下几个区别： 首先，GitOps 是以目标为导向的。它使用 Git 来维护期望状态，并不断调整实际状态，最终与期望状态相匹配。而 DevOps 更多关注的是最佳实践，这些实践可以普遍应用于企业的每一个流程。 其次，GitOps 采取声明式的操作方法，而 DevOps 同时接受声明式和命令式的方法，所以 DevOps 除了适用于容器环境之外，还适用于虚拟机和裸机环境。 最后，GitOps 重新定义了云原生场景下的 CI/CD，它以 Git 作为中心的不可变状态声明，以加快持续部署速度。 GitOps 的设计哲学 想要使用 GitOps 来管理你的基础设施和应用，需要践行以下几个原则： 1. 声明式 必须通过声明式来描述系统的期望状态。例如 Kubernetes，众多现代云原生工具都是声明式的，Kubernetes 只是其中的一种。 2. 版本控制/不可变 因为所有的状态声明都存储在 Git 仓库中，并且把 Git 仓库作为单一事实来源，那么所有的操作都是从 Git 仓库里驱动的，而且保留了完整的版本历史，方便回滚。有了 Git 优秀的安全保障，也可以使用 SSH 密钥来签署 commits，对代码的作者和出处实施强有力的安全保障。 3. 自动应用变更 Git 仓库中声明的期望状态发生了任何变更，都可以立即应用到系统中，而且不需要安装配置额外工具（比如 kubectl），也不需要配置 Kubernetes 的认证授权。 4. 持续的 Reconciliation Reconciliation 其实最早是 Kubernetes 里的一个概念，表示的是确保系统的实际状态与期望状态一致的过程。具体的实现方式是在目标环境中安装一个 agent，一旦实际状态与期望状态不匹配，agent 就会进行自动修复。这里的修复比 Kubernetes 的故障自愈更高级，即使是手动修改了集群的编排清单，集群也会被恢复到 Git 仓库中的清单所描述的状态。 鉴于以上这些设计哲学，我们来看一下 GitOps 的工作流： 首先，团队中的任何一个成员都可以 Fork 仓库对配置进行更改，然后提交 Pull Request。 接下来会运行 CI 流水线，一般会做这么几件事情：验证配置文件、执行自动化测试、检测代码的复杂性、构建 OCI 镜像、将镜像推送到镜像仓库等等。 CI 流水线运行完成后，团队中拥有合并代码权限的人将会将这个 Pull Request 合并到主分支中 。一般拥有这个权限的都是研发人员、安全专家或者高级运维工程师。 最后会运行 CD 流水线，将变更应用到目标系统中（比如 Kubernetes 集群或者 AWS） 。 整个过程完全自动化且透明，通过多人协作和自动化测试来保证了基础设施声明配置的健壮性。而传统的模式是其中一个工程师在自己的电脑上操作这一切，其他人不知道发生了什么，也无法对其操作进行 Review。 Push vs Pull CD 流水线有两种模式：Push 和 Pull。 Push 模式 目前大多数 CI/CD 工具都使用基于 Push 的部署模式，例如 Jenkins、CircleCI 等。这种模式一般都会在 CI 流水线运行完成后执行一个命令（比如 kubectl）将应用部署到目标环境中。 这种 CD 模式的缺陷很明显： 需要安装配置额外工具（比如 kubectl）； 需要 Kubernetes 对其进行授权； 需要云平台授权； 无法感知部署状态。也就无法感知期望状态与实际状态的偏差，需要借助额外的方案来保障一致性。 Kubernetes 集群或者云平台对 CI 系统的授权凭证在集群或云平台的信任域之外，不受集群或云平台的安全策略保护，因此 CI 系统很容易被当成非法攻击的载体。 Pull 模式 Pull 模式会在目标环境中安装一个 Agent，例如在 Kubernetes 集群中就靠 Operator 来充当这个 Agent。Operator 会周期性地监控目标环境的实际状态，并与 Git 仓库中的期望状态进行比较，如果实际状态不符合期望状态，Operator 就会更新基础设施的实际状态以匹配期望状态。 只有 Git 的变更可以作为期望状态的唯一来源，除此之外，任何人都不可以对集群进行任何更改，即使你修改了，也会被 Operator 还原为期望状态，这也就是传说中的不可变基础设施。 目前基于 Pull 模式的 CD 工具有 Argo CD， Flux CD 以及 ks-devops。 GitOps 的优势 一般 GitOps 首选的都是基于 Pull 的部署模式，因为这种模式有很多不可替代的优势。 更强大的安全保障 上面已经提到了，使用 GitOps 不需要任何 Kubernetes 或者云平台的凭证来执行部署，Kubernetes 集群内的 Argo CD 或者 Flux CD 只需要访问 Git 仓库，并通过 Pull 模式来更新即可。 另一方面，Git 由用于跟踪和管理代码变更的强大密码学支持，拥有对变更进行签名以证明作者身份和来源的能力，这是保障集群安全的关键。 Git 作为事实的唯一真实来源 因为所有的应用包括基础设施的声明式配置都保存在 Git 中，并把 Git 作为应用系统的唯一事实来源，因此可以利用 Git 的强大功能操作所有东西，例如版本控制、历史记录、审计和回滚等等，无需使用 kubectl 这样的工具来操作。 提高生产力 Git 也是开发人员非常熟悉的工具，通过 Git 不断迭代，可以提高生产率，加快开发和部署速度，更快地推出新产品，同时提高系统的稳定性和可靠性。 更容易合规的审计 使用 GitOps 的基础设施可以像任何软件项目一样使用 Git 来管理，所以同样可以对其进行质量审计。当有人需要对基础设施进行更改时，会创建一个 Pull Request，等相关人员对其进行 Code Review 之后，更改才可以应用到系统中。 总结 GitOps 是对现有 DevOps 文化的补充，它使用 Git 这样的版本控制系统来自动部署基础设施，部署过程清晰可见，可以查看和跟踪对系统进行的任何变更，提高了生产力、安全性和合规性。而且 GitOps 提供了更优雅的可观测性，可以实时观测部署状态，并采取行动使实际状态与期望状态保持一致。 而且在 GitOps 中，整个系统都是通过声明式来描述的，天然适合云原生环境，因为 Kubernetes 也是这么设计的。 参考资料 What is GitOps and what should you know about it? DevOps vs GitOps: 4 Benefits you must know to Master the Methodologies Guide To GitOps","tags":["Workflow","GitOps","DevOps"],"categories":["Git"]},{"title":"Design pattern in Gitlay(Git PRC service)","path":"/posts/341c748.html","content":"这篇文章源于偶然看到的一篇文章# Golang技巧之默认值设置的高阶玩法，它讲的是 GRPC 中的设计模式。而我没有研究过 GRPC 源码，看起来稍显陌生。但好在手头上有 Gitaly 源码，算是稍微熟悉它的源码，因此想看看这个项目里面是不是也应用到了前面文章里讲的高阶用法，简单搜索一下源码后，发现这种代码模式还挺多的，于是趁热记录了其中一小段阅读结果。 Gitaly is a Git RPC service for handling all the git calls made by GitLab repo: gitaly: https://gitlab.com/gitlab-org/gitaly git rev-list 是 Git 中非常重要和有用的命令，它存在许多选项以及子命令，Gitaly 中对这些选项和命令进行了封装。 首先定义了一个 config 结构体，包含不同的配置选项： 123456789101112131415type ObjectType stringtype revlistConfig struct &#123; blobLimit int objects bool objectType ObjectType order Order reverse bool maxParents uint disabledWalk bool firstParent bool before, after time.Time author []byte skipResult func(*RevisionResult) bool&#125; 然后定义一个函数，该函数的参数是上述结构体，且是指针类型参数，这点非常重要，它使得这个函数能够直接修改入参 cfg： 1type RevlistOption func(cfg *revlistConfig) 然后是一系列对 git-rev-list 参数进行修改的方法，每个 WithXXX 方法调用前面的匿名函数，并返回 RevlistOption 类型变量： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556func WithBlobLimit(limit int) RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.blobLimit = limit &#125;&#125;func WithObjectTypeFilter(t ObjectType) RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.objectType = t &#125;&#125;func WithRevrse() RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.reverse = true &#125;&#125;func WithMaxParents(p uint) RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.maxParents = p &#125;&#125;func WithDisabledWalk() RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.disabledWalk = true &#125;&#125;func WithFirstParent() RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.firstParent = true &#125;&#125;func WithBefore(t time.Time) RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.before = t &#125;&#125;func WithAfter(t time.Time) RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.after = t &#125;&#125;func WithAuthor(author []byte) RevlistOption &#123; return func(cfg *revlistConfig) &#123; cfg.author = author &#125;&#125;// 省略... git-rev-list 方法定义如下： 123456func Revlist( ctx context.Context, repo *localrepo.Repo, revisions []string, options ...RevlistOption,) RevisionIterator 在 Revlist() 中最后一个参数 options ...RevlistOption，它表示是不定长变参列表具体参数数量交给调用者。 具体实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100func Revlist( ctx context.Context, repo *localrepo.Repo, revisions []string, options ...RevlistOption,) RevisionIterator &#123; // 定义一个config配置变量 var cfg revlistConfig // 注意这里，遍历options中每一个方法，每个方法都会对config变量进行赋值、修改 for _, option := range options &#123; option(&amp;cfg) &#125; resultChan := make(chan RevisionResult) // 使用goroutine丢到后台运行 go func() &#123; defer close(resultChan) // 定义git option变量flags flags := []git.Option&#123;&#125; // 下面几项都是根据cfg配置, 更新flag变量 if cfg.objects &#123; flags = append(flags, git.Flag&#123;Name: &quot;--in-commit-order&quot;&#125;, git.Flag&#123;Name: &quot;--objects&quot;&#125;, git.Flag&#123;Name: &quot;--object-names&quot;&#125;, ) &#125; if cfg.blobLimit &gt; 0 &#123; flags = append(flags, git.Flag&#123; Name: fmt.Sprintf(&quot;--filter=blob:limit=%d&quot;, cfg.blobLimit), &#125;) &#125; if cfg.objectType != &quot;&quot; &#123; flags = append(flags, git.Flag&#123;Name: fmt.Sprintf(&quot;--filter=object:type=%s&quot;, cfg.objectType)&#125;, git.Flag&#123;Name: &quot;--filter-provided-objects&quot;&#125;, ) &#125; /// 此处省略更多项cfg配置 // 配置完成后，执行git-rev-list命令 var stderr strings.Builder revlist, err := repo.Exec(ctx, git.SubCmd&#123; Name: &quot;rev-list&quot;, Flags: flags, Args: revisions, &#125;, git.WithStderr(&amp;stderr), ) // 此处省略错误处理 // 对结果的每行进行处理 scanner := bufio.NewScanner(revlist) for scanner.Scan() &#123; line := make([]byte, len(scanner.Bytes())) copy(line, scanner.Bytes()) oidAndName := bytes.SplitN(line, []byte&#123;&#x27; &#x27;&#125;, 2) result := RevisionResult&#123; OID: git.ObjectID(oidAndName[0]), &#125; // 省略... if isDone := sendRevisionResult(ctx, resultChan, result); isDone &#123; return &#125; &#125; // scan结束 if err := scanner.Err(); err != nil &#123; sendRevisionResult(ctx, resultChan, RevisionResult&#123; err: fmt.Errorf(&quot;scanning rev-list output: %w&quot;, err), &#125;) return &#125; // 等待goruntine结束 if err := revlist.Wait(); err != nil &#123; sendRevisionResult(ctx, resultChan, RevisionResult&#123; err: fmt.Errorf(&quot;rev-list pipeline command: %w, stderr: %q&quot;, err, stderr.String()), &#125;) return &#125; &#125;() // 返回结果 return &amp;revisionIterator&#123; ch: resultChan, &#125;&#125; 那么如何调用这个方法呢？搜索 Gitaly 源码可以看到： 在ListBlobs 中是这样用的： 1234567891011121314func (s *server) ListBlobs(req *gitalypb.ListBlobsRequest, stream gitalypb.BlobService_ListBlobsServer) error &#123; // 省略... // 定义一个RevlistOption变量，向里面注入多个配置选项 revlistOptions := []gitpipe.RevlistOption&#123; gitpipe.WithObjects(), gitpipe.WithObjectTypeFilter(gitpipe.ObjectTypeBlob), &#125; // 调用Revlist() revlistIter := gitpipe.Revlist(ctx, repo, req.GetRevisions(), revlistOptions...) // 省略...&#125; ListCommits 中根据请求中不同的 case 分别向 revlistOptions 变量追加不同的配置选项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950func (s *server) ListCommits( request *gitalypb.ListCommitsRequest, stream gitalypb.CommitService_ListCommitsServer,) error &#123; // 省略... ctx := stream.Context() repo := s.localrepo(request.GetRepository()) // 定义一个revlistOptions变量 revlistOptions := []gitpipe.RevlistOption&#123;&#125; // 省略... /// 根据不同的case向revlistOptions追加不同的配置 if request.GetReverse() &#123; revlistOptions = append(revlistOptions, gitpipe.WithReverse()) &#125; if request.GetMaxParents() &gt; 0 &#123; revlistOptions = append(revlistOptions, gitpipe.WithMaxParents(uint(request.GetMaxParents()))) &#125; if request.GetDisableWalk() &#123; revlistOptions = append(revlistOptions, gitpipe.WithDisabledWalk()) &#125; if request.GetFirstParent() &#123; revlistOptions = append(revlistOptions, gitpipe.WithFirstParent()) &#125; if request.GetBefore() != nil &#123; revlistOptions = append(revlistOptions, gitpipe.WithBefore(request.GetBefore().AsTime())) &#125; if request.GetAfter() != nil &#123; revlistOptions = append(revlistOptions, gitpipe.WithAfter(request.GetAfter().AsTime())) &#125; if len(request.GetAuthor()) != 0 &#123; revlistOptions = append(revlistOptions, gitpipe.WithAuthor(request.GetAuthor())) &#125; // 调用Revlist() revlistIter := gitpipe.Revlist(ctx, repo, request.GetRevisions(), revlistOptions...) // 省略后续... return nil&#125; ListLFSPointers 中省略定义 RevlistOption 变量，直接利用 Revlist 方法中不定参数特性，添加不同的配置选项： 123456789101112131415func (s *server) ListLFSPointers(in *gitalypb.ListLFSPointersRequest, stream gitalypb.BlobService_ListLFSPointersServer) error &#123; ctx := stream.Context() // 省略... repo := s.localrepo(in.GetRepository()) // 省略... // 调用Revlist() revlistIter := gitpipe.Revlist(ctx, repo, in.GetRevisions(), gitpipe.WithObjects(), gitpipe.WithBlobLimit(lfsPointerMaxSize), gitpipe.WithObjectTypeFilter(gitpipe.ObjectTypeBlob), ) /// 省略后续...&#125; 总结： 这种设计模式对于多配置，多参数的方法非常适合，虽然代码实现起来有点麻烦，但是可读性强，使用灵活。这种模式还有一些变体，后面有时间再记录一下。","tags":["Design-Pattern"],"categories":["Git"]},{"title":"git bundle 格式及应用","path":"/posts/32c910d1.html","content":"git-bundle 文件是一种将 git objects 数据(git packfile)与仓库引用 refs 结合在一起的一种数据包格式，通过 objects + refs 就能恢复出一个完整的 git 仓库，因此可以用 git-bundle 文件来备份 git 仓库。 格式 git bundle v2 格式： 12345678bundle = signature *prerequisite *reference LF packsignature = &quot;# v2 git bundle&quot; LFprerequisite = &quot;-&quot; obj-id SP comment LFcomment = *CHARreference = obj-id SP refname LFpack = ... ; packfile git bundle v3 格式： 1234567891011bundle = signature *capability *prerequisite *reference LF packsignature = &quot;# v3 git bundle&quot; LFcapability = &quot;@&quot; key [&quot;=&quot; value] LFprerequisite = &quot;-&quot; obj-id SP comment LFcomment = *CHARreference = obj-id SP refname LFkey = 1*(ALPHA / DIGIT / &quot;-&quot;)value = *(%01-09 / %0b-FF)pack = ... ; packfile 注：以上均采用 ABNF 标记法 可以看出： git bundle v2 包含四个部分： 签名。标识 git bundle 版本 必要依赖。不包含在当前 bundle包 中，但是被 bundle包 中的数据引用到的数据。 引用。当前 bundle包 中包含的引用。 pack文件。git packfile git bundle v3 仅比 v2 多了一个 capability 部分。 前面提到过 prerequisite 的概念，其格式为 prerequisite = &quot;-&quot; obj-id SP comment LF，所以来看下这个实际是什么意思。 1234567891011121314# 先打包master分支上最近三次提交$ git bundle create recent.bundle master~3..masterEnumerating objects: 13, done.Counting objects: 100% (13/13), done.Compressing objects: 100% (8/8), done.Total 9 (delta 3), reused 0 (delta 0), pack-reused 0# 再用 git bundle verify 验证一下这个bundle包有没有外部依赖$ git bundle verify recent.bundleThe bundle contains this ref:0a831168aa94dffaa92f5d73f3e873ef5fd89603 refs/heads/masterThe bundle requires this ref:d5d9b1c95f0012cb7da18deaff6a806f89e48867recen.bundle is okay 上面的结果很明显： 12The bundle requires this ref:d5d9b1c95f0012cb7da18deaff6a806f89e48867 再打开这个bundle包文件看下： 123# v2 git bundle-d5d9b1c95f0012cb7da18deaff6a806f89e48867 demo.tar.gz0a831168aa94dffaa92f5d73f3e873ef5fd89603 refs/heads/master 第二行的内容 -d5d9b1c95f0012cb7da18deaff6a806f89e48867 demo.tar.gz 即是prerequisite 并且符合格式 prerequisite = &quot;-&quot; obj-id SP comment LF 我们看一个实际的 git pack 文件： 12345678PACK^@^@^@^B^@^@^@^C&lt;91&gt;^Kx^A^A±^@Nÿtree 212ccb4755ab7c489bee69200388139d7f081e7cauthor Li Linchao &lt;lilinchao@oschina.cn&gt; 1646124003 +0800committer Li Linchao &lt;lilinchao@oschina.cn&gt; 1646124003 +0800add aa.txt©&amp;5A5x^A^A^E^@úÿaaaa^E]^A&lt;8f&gt;¢^Bx^A^A&quot;^@Ýÿ100644 aa.txt^@]0&lt;8e&gt;^]^F^K^L8&#125;E,ôt^?&lt;89&gt;ì¹&lt;93&gt;XQ£÷^KlK&lt;9a&gt;&lt;93&gt;pÃ^@ò&amp;bL37©&lt;85&gt;(ÐâWa^X~ 而此时的 git bundle v2 文件如下： git bundle create master.bundle master 12345678910# v2 git bundlee0caba68a7281d4ff86693745a1617ffc72c3e7d refs/heads/masterPACK^@^@^@^B^@^@^@^C&lt;91&gt;^Kx^A^A±^@Nÿtree 212ccb4755ab7c489bee69200388139d7f081e7cauthor Li Linchao &lt;lilinchao@oschina.cn&gt; 1646124003 +0800committer Li Linchao &lt;lilinchao@oschina.cn&gt; 1646124003 +0800add aa.txt©&amp;5A¢^Bx^A^A&quot;^@Ýÿ100644 aa.txt^@]0&lt;8e&gt;^]^F^K^L8&#125;E,ôt^?&lt;89&gt;ì¹&lt;93&gt;XQ£÷^Kl5x^A^A^E^@úÿaaaa^E]^A&lt;8f&gt;,^B&lt;9d&gt;ï&lt;89&gt;DIr^\\&lt;87&gt;*&lt;9b&gt;Æû^X¹É&#125;PÖ git bundle v3 文件如下: git bundle create --version=3 master-v3.bundle master 1234567891011# v3 git bundle@object-format=sha1e0caba68a7281d4ff86693745a1617ffc72c3e7d refs/heads/masterPACK^@^@^@^B^@^@^@^C&lt;91&gt;^Kx^A^A±^@Nÿtree 212ccb4755ab7c489bee69200388139d7f081e7cauthor Li Linchao &lt;lilinchao@oschina.cn&gt; 1646124003 +0800committer Li Linchao &lt;lilinchao@oschina.cn&gt; 1646124003 +0800add aa.txt©&amp;5A¢^Bx^A^A&quot;^@Ýÿ100644 aa.txt^@]0&lt;8e&gt;^]^F^K^L8&#125;E,ôt^?&lt;89&gt;ì¹&lt;93&gt;XQ£÷^Kl5x^A^A^E^@úÿaaaa^E]^A&lt;8f&gt;,^B&lt;9d&gt;ï&lt;89&gt;DIr^\\&lt;87&gt;*&lt;9b&gt;Æû^X¹É&#125;PÖ 操作实践 在机器A中的仓库 R1 中： 123$ git bundle create file.bundle master# 做个标记$ git tag -f lastR2bundle master 将 file.bundle 转移到机器B上，克隆仓库 R2： 1234$ git clone -b master /path/to/file.bundle R2Cloning into &#x27;R2&#x27;...Receiving objects: 100% (38/38), 7.97 KiB | 7.97 MiB/s, done.Resolving deltas: 100% (6/6), done. 回到仓库 R1，仓库 R1 有了新的提交。然后继续打包： 123$ git bundle create file.bundle lastR2bundle..master# 做个标记，下次打包时使用$ git tag -f lastR2bundle master 将 file.bundle 转移到机器 B 上，再到 R2 仓库中进行更新： 12345678910111213$ git fetchReceiving objects: 100% (41/41), 8.28 KiB | 8.28 MiB/s, done.Resolving deltas: 100% (7/7), done.From /home/git/test-git/example/repo.bundle d4f54d9..6a33e12 master -&gt; origin/master # 还是在cloned-repo中$ git ls-remoteFrom /path/to/file.bundle6a33e12f3d7116863a19bf48471c74c597421f8a HEAD45eab37d3cb8b5be02a59d3690cb63d3f692f6b9 refs/remotes/origin/master45eab37d3cb8b5be02a59d3690cb63d3f692f6b9 refs/remotes/origin/HEAD6a33e12f3d7116863a19bf48471c74c597421f8a refs/heads/master 以上操作，看起来都跟读取 Git 远程仓库的一样。 但是不支持写仓库操作，即 git push 操作。 以上操作就完成了仓库的全量备份和增量备份。 还可以用其它形式进行打包： 123$ git bundle create mybundle v1.0.0..master$ git bundle create mybundle --since=10.days master$ git bundle create mybundle -10 master 只要是 git rev-list 能接受的参数，就可以放在 git bundle create mybundle 后面。比如可以使用 --max-age 选项，实现根据时间戳来进行备份，大致过程如下： 1234567891011121314151617```Bash# 当前HEAD的时间戳，作为下次备份的起点时间$ git cat-file commit HEAD | sed -n &quot;s/^committer .*&gt; \\([0-9]*\\) .*/\\1/p&quot; 1660809497# --branches 获取refs/heads/下所有相关commits# --tags 获取refs/tags/下所有相关commits# --remotes 获取refs/remotes/下所有相关commits# --all 获取refs/下所有相关commits# --objects 表示commit所关联的所有对象$ git bundle create latest.bundle --max-age=1660807920 --all --objects# 获取bundle包中的引用信息，可以通过其它选项筛选出部分引用。$ git bundle list-heads latest.bundle &gt; latest.list# 通过git-ls-remote获取bundle包中的所有引用信息。$ git ls-remote latest.bundle &gt; latest.lsremote 应用 目前 Gitlab 的仓库导出、导入功能以及阿里云效 CodeUp 的仓库备份功能主要就是利用 Git-bundle 特性对 Git 仓库进行打包。 参考链接 https://git-scm.com/docs/git-bundle https://git-scm.com/docs/bundle-format","tags":["Git-bundle"],"categories":["Git"]},{"title":"学习 Rust 的一些笔记","path":"/posts/767b1d3c.html","content":"Rust是一门偏底层的，安全的，高效的开源编程语言。 工具链 rustup 是管理Rust版本和相关工具的命令行工具(rust toolchain installer) rustup update 更新Rust版本 rustup self uninstall 卸载Rust以及rustup本身 Rust工具链中包括rustc编译器工具，rustfmt格式化工具，rustdoc文档化工具等。 rustc类似于C/C++中的gcc/clang Cargo 是 Rust 的构建系统和包管理器。可以进行构建代码、下载依赖库并编译这些库等。 cargo new rust-proj 创建一个Rust项目， 123456789$ cargo new rust-proj Created binary (application) `rust-proj` package$ tree rust-projrust-proj├── Cargo.toml└── src └── main.rs1 directory, 2 files Cargo会在 hello_cargo 目录初始化一个 git 仓库，以及一个.gitignore文件。如果你在现有的 git 仓库中运行 cargo new，则不会生成 git 文件；你可以通过使用cargo new --vcs=git 来覆盖此行为。 可以通过 --vcs 参数使 cargo new 切换到其它版本控制系统（VCS），或者不使用 VCS。运行 cargo new --help 参看可用的选项。 cargo build构建项目，目标可执行文件在target/debug/下 cargo run则是构建项目并运行。 cargo check 检查项目代码正确，确保可编译。不会产生可执行文件。 cargo build默认构建是debug模式。如果项目一切都OK，可以运行cargo build --release执行发布构建，这会对项目进行一定编译优化，从而使得代码运行得更快，但是相应地，编译时间会更长。 cargo doc --open 会生成当前项目中的依赖库(crate)的文档，并转到浏览器可以查询。 Hello, World! 123fn main() &#123; println!(&quot;Hello, world!&quot;);&#125; println! 调用了一个 Rust 宏（macro）。如果是调用函数，则应输入 println（没有!）。我们将在第十九章详细讨论宏。现在你只需记住，当看到符号 ! 的时候，就意味着调用的是宏而不是普通函数，并且宏并不总是遵循与函数相同的规则。 cargo new生成的项目中，包含配置文件Cargo.toml 文件名: Cargo.toml 123[dependencies]rand = &quot;0.8.3&quot; 其中“0.8.3”指定依赖版本，其语法遵循语义化版本（Semantic Versioning） 这里的0.8.3 实际上是 ^0.8.3 的简写，它表示 任何不低于 0.8.3， 但是低于 0.9.0 的版本。Cargo将这些版本视作与 0.8.3 版本公有 API 相兼容的版本，这个声明确保你将获得最新的补丁版本，它仍然可以与本章中的代码正常编译。0.9.0 或以上版本不保证拥有接下来示例中使用到的API。 一些定义 Rust变量默认是不可改变的（immutable），如果想声明可变变量，需要使用mut关键字。 Rust不允许对常量使用 mut。常量不光默认不能变，它总是不能变。其声明使用const，且必须标注类型。 整型变量分有符号和无符号，如i8表示有符号8位整数，u8表示无符号8位整数，i128表示有符号128位整数。 还有一种整型依赖计算机架构，isize, usize在不同的架构中表示的长度会不同。 整型字面值有十六进制(0xff)，八进制(0o77)，二进制(0b11)，以及十进制(99_999)，单字节字符(仅限u8) Rust默认数字类型是i32 浮点型变量有两种，f32表示单精度浮点小数，f64表示双精度浮点小数。默认是f64。 字符类型（char）用单引号表示，其大小为4个字节，表示了一个Unicode标量值。 复合类型元组(tuple)一旦声明，其长度不变，其中每一个位置都有一个类型的值，类型可以不同。 复合类型数组(array)长度也是固定的，而且其中类型必须相同。 语句(statement)和表达式(expression) Rust是一门基于表达式的语言。 语句是执行一些操作，但是不返回值的指令。 函数定义就是一个语句。 表达式计算并产生一个值，可以赋予其它变量。 函数调用是一个表达式，大括号创建的块作用域也是一个表达式。 表达式的结尾没有分号，如果结尾加上分号，则变成了语句。 数字本身就是一个表达式，所以它可以返回本身的值赋值给其它变量。 栈(stack)中的数据必须占用已知且大小固定的大小。 当数据大小未知，或大小可能变化的时候，需要用堆(heap)。比如使用内存分配器memory allocator分配指定大小的内存，此时该块内存会被标记为已用，并且以指针来表示这块内存。 而将数据放入栈中的过程并不叫做分配内存，因为这个过程并没有新的内存被分配。 堆的指针可以存储在栈上。 入栈比在堆上分配内存要快。 访问堆中的数据比访问栈上的数据要慢，因为访问堆首先要通过指针来访问，而指针在栈上。 一些笔记 定义变量用动词let 借鉴Python的元组 借鉴C++的指针 完善的包管理工具cargo 友好的文档管理 使用先进的VCS管理项目 无垃圾回收机制，使用变量所有权管理内存 编译与执行分开，更早的发现错误 浅拷贝与深拷贝，默认不进行数据的深拷贝，深拷贝使用clone方法 移动(move)操作 Copy trait 栈上数据；堆上数据；既在栈上，又在推上(数据指针在栈上，数据内容在堆上)数据 默认行为：默认变量不可变 引用(ref)变量默认也不能修改其引用的值 一个引用的作用域从声明的地方开始一直持续到最后一次使用为止 字符串slice Rust可以直接将数据附加到枚举的每个成员上，这样就不需要一个额外的结构体了。 1234567enum IpAddr &#123; V4(String), V6(String),&#125;let home = IpAddr::V4(String::from(&quot;127.0.0.1&quot;));let loopback = IpAddr::V6(String::from(&quot;::1&quot;)); Rust没有空值(Null)，因为空值会导致很多错误，而是实现了一个枚举变量Option&lt;T&gt;： 1234567891011enum Option&lt;T&gt; &#123; Some(T), None,&#125;let some_number = Some(5);let some_string = Some(&quot;a string&quot;);# 当为None时，必须显示指定类型&lt;T&gt;let absent_number: Option&lt;i32&gt; = None; 关于字符串方法，以下两种方法等效： 12let s1 = String::from(&quot;initial contents&quot;);let s2 = &quot;initial contents&quot;.to_string(); 参考链接： rust中文官网 rust book rust course","tags":["Rust"],"categories":["Rust"]},{"title":"认证(Authentication)和授权(Authorization)","path":"/posts/3be69b54.html","content":"什么是认证和授权 认证(Authentication)，识别身份 授权(Authorization)，授予被识别的身份是否有权限获取指定资源，或授予其操作权限 认证的双方是访问者(User)、身份信息持有者(IdP/Identity Provider)。 用户持有的唯一标识符(用户名，UUID 等)，密码信息（密码，指纹等）需要与IdP持有的信息匹配才能认证成功。 资源持有者(Source Owner)，控制资源的获取，修改，删除等。 身份和资源的分离 资源可能是用户自己产生的，也可能是第三方服务器产生的，或者叫做 Service Provider(SP)，也称 Client。 身份和资源的分离即为 IdP, SP 分离。 IdP 与 IdP 之前也可以进行资源传递，并授权。这种方式一般称为联邦授权。 LDAP LDAP(Light Directory Access Protocol)即轻量级目录访问协议，它是一种为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据，所以大多数是用来查询的。LDAP 只是一种协议，可以有多种实现。 一般结构： DIT(Directory Information Tree）目录信息树 dn(Distinguished Name)：一条记录的详细位置，相当于绝对路径(唯一) rdn(Relative dn) : 相对dn, 相对于相对路径 dc(Domain Component) ：一条记录所属区域 (哪一颗树) ou(Organization Unit) ：一条记录所属组织 （哪一个分支） cn/uid(Common Name/user id)：一条记录的名字/ID (哪一个苹果名字) sn(Surname): 名字前缀(姓) 基本模型： 信息模型，将信息以树状方式组织，基本数据单元是条目(Entry), 条目又由不同属性组成 命名模型，实现一种条目定位方式 功能模型，实现增删改查等功能 安全模型，实现身份认证，安全通道，访问控制 OAuth2.0 OAuth 2.0 是一个授权标准协议，主要用于资源授权。 前面提到的身份和资源的分离，OAuth 引入了一个授权层，用来分离两种不同的角色：客户端和资源所有者。资源所有者同意以后，资源服务器可以向客户端颁发令牌。客户端通过令牌，去请求数据。 所以，OAuth 的核心就是向第三方应用颁发令牌。 根据 OAuth 2.0 协议规范，主要有四个主体： 授权服务器(Authorization Server)，负责颁发 Access Token，Authing 是授权服务器。 资源所有者(Resource Owner)，即用户，授权其他人访问他的资源。 调用方(Client)，即第三方应用。调用方请求获取 Access Token，经过用户授权后，授权服务器为其颁发 Access Token。调用方可以携带 Access Token 到资源服务器访问用户的资源。 资源服务器(Resouce Server)，存储用户资源。收到 Access Token 后，验证它的被赋予的权限项目，最后返回资源。 这个过程可能还存在其它主体，如浏览器，也称用户代理(User Agent), 服务提供商(Server Provider)等。 客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0 定义了四种授权方式。 授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 授权码模式（authorization code）是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与&quot;服务提供商&quot;的认证服务器进行互动。 它的步骤如下： （A）用户访问客户端，后者将前者导向认证服务器。 （B）用户选择是否给予客户端授权。 （C）假设用户给予授权，认证服务器将用户导向客户端事先指定的&quot;重定向URI&quot;（redirection URI），同时附上一个授权码。 （D）客户端收到授权码，附上早先的&quot;重定向URI&quot;，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。 （E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。 OIDC OIDC(OpenID Connect ) 是 OAuth 2.0 协议的超集，能够认证用户并完成资源授权。OIDC的认证和授权分为四种模式：授权码模式（Code）、隐式模式（Implicit）、密码模式（Password）、客户端证书模式（Client Credential） 除了 OIDC 协议之外，还存在着许多标准身份协议，例如 SAML 和 CAS。它们的存在意义都是类似的：为了能让素不相识的 SP 和 IdP 进行快速对接，在用户的许可下让 SP 在 IdP 处完成授权，从而访问 IdP 下资源提供者的资源。 参考链接 理解OAuth 2.0 - 阮一峰的网络日志 OIDC 与 OAuth2.0 综述","tags":["OAuth2.0","LDAP","OIDC"],"categories":["Auth"]},{"title":"一种 Git 插件工具：git repo-clean","path":"/posts/92e91caf.html","content":"本篇文章将从如何定义 Git 大仓库，大仓库如何产生，大仓库的负面影响等方面讨论起，然后介绍几款目前针对大仓库的处理工具，并讨论它们的优缺点，然后谈谈我们今天要介绍的新工具git repo-clean的一些设计目标，并重点介绍它的设计原理。 作为国内最大的代码托管平台，Gitee 每天都有大量不同行业的人在上面围绕 Git 仓库进行各种 Git 操作实践。 但是我们经常收到用户的帮助请求，他们的问题往往是其 Git 仓库变得非常大，这影响了他们对仓库做进一步的操作，甚至会导致开发进度落后。 实际场景： 场景一： 用户不小心使用 git add . 将当前工作区中的所有文件加入到 Git 仓库，并做了提交，但是后来意识到有些文件并不是想要的，如 build/、ThirdPart/、vendor/等目录下的文件，于是想删除掉之前的提交中的部分文件。一般情况下，可以使用 git reset或者 git revert回退当前的 bad commit到它的前一次 commit。但是，由于已经提交了很多正常的有用的 commit，这个时候再回退就需要小心了，因为所有 bad commit 之后的所有正常提交也会被回退。 场景二： 在一个成熟的项目中经过多年的迭代，项目的功能变得与以前非常不同，不断地代码迭代也使得 Git 仓库变得臃肿，再加上在用 Git 管理项目的前期由于使用的不成熟，向仓库提交了很多不必要的文件，这些文件长期存在，而且如果对一个大文件进行过多次修改，每个版本都会完整保存在仓库中，则体积也会成倍增长。之后推送到服务端仓库，也会占用相当大的服务端仓库资源。同时，在协作开发的情况下，意味着每个人都会克隆一个巨大的仓库到本地，而且由于数据量很大，该过程变得很慢。 问题： 基于以上场景，可以归纳出 Git 仓库的几种常见的问题： 向仓库中提交了大量不必要的文件。如：项目编译过程文件，第三方库文件，多媒体文件等。这导致 Git 仓库的提交文件被污染。 向仓库中提交的单个文件非常大。假如提交了一个 100M 的文件，一方面平台会限制用户推送单个文件大小超过 100M 的文件；另一方面，如果多次修改过这个文件，仓库中将会存在多个版本，比如经过10次修改，每个版本大约还是 100M，那仓库就会因为这个文件，体积变为 10 * 100M，这样仓库总的大小也会变得巨大，也将超过推送限额。 以上都属于是 Git 大仓库问题，根据经验法则，大仓库的衡量维度包括： 单个文件是否过大 文件数量是否过多, 如数量超过100k 提交数量是否过多，如数量超过100K 分支数/标签数是否过多，如数量超过10K 子模块是否过多，如超过25个子模块 关于 Git 大仓库的详细说明，可见这篇文章[1]。 以上衡量标准并不是固定的，只是根据经验所得，是一种参考值，其衡量值往往随着电脑的性能，系统的类型，以及Git 的版本不同而不同。 但是根据这种衡量标准，我们大致能知道怎么样的仓库才算得上大仓库。 我们收到的大仓库问题反馈一般集中在前两种。通常，当出现仓库数据过大的信号后，用户一开始往往会选择删除仓库当前工作区下的文件，而忽略了 Git 仓库是分为工作区，缓存区，对象存储区的结构。当文件提交后，不仅工作区存在该文件，对象存储区也存在该文件，所以只删除工作区的文件，虽然肉眼看不见文件了，但其实它还是存在仓库中，通过一些git命令很容易将它恢复到当前工作区。这说明仓库体积并没用有效的减少。 一方面，Git 是生来是为源代码文件而设计和优化的，而源代码文件一般都不会很大，对于大仓库，Git 的很多操作的性能产生非常大的影响，如果大仓库中问非常多，那么在有遍历操作的git命令的时候就非常耗时；另一方面，Git 是分布式的，一个仓库通常包含所有的修改版本、提交历史。大仓库的数据存储和传输会有一定压力，比如传输很慢，传输超时，或者存储空间不足导致传输失败等。 我们很多时候很难避免制造Git大仓库，所以这些问题很容易出现。对Git的操作比较熟悉的人，会在项目刚开始的时候，通过.gitignore 文件[2]来管理提交到仓库的文件。 在Gitee上新建仓库时，也会提供.gitignore模板文件: 如果仓库中没有这个文件，需要手动新建。 这个文件的作用是将指定类型，或者指定目录下的文件忽视掉，Git就不会将这些文件加入到仓库中，从而保持仓库干净。 使用.gitignore管理仓库文件只是防止仓库污染、体积膨胀的手段之一。 另外一种手段是使用Git LFS 专门来管理仓库大文件，从而避免仓库体积膨胀。 该功能的原理是，使用专门的大文件存储服务器来管理仓库中特定的大文件，而本地仓库只管理大文件的指针。详情可参考：Git LFS 操作指南[3]。 如果是仓库中已经存在大量非必要大文件而导致仓库体积膨胀，那么如何解决呢？其实已经有人做出了一些工具，来试图解决此类问题。 我们先来看下几种常见的工具的对比： 同类工具对比： git-filter-branch[4] 特点： Git 内部自带的命令，只要有 Git 环境，就能使用这个工具。 使用示例： 12345$ git filter-branch --tree-filter &#x27;rm -f path/to/large/file&#x27; --tag-name-filter cat -- --all$ git reflog expire --expire=now --all$ git gc --prune=now --aggressive$ git push origin --tags --force$ git push origin --all --force 问题： 使用起来比较复杂； 如果不确定大文件，需要先使用其它命令手动扫描仓库中存在的大文件； 处理过程特别慢[5]!； 如果存在特殊文件名，特殊文件路径，可能会出错，甚至误删文件； 删除文件、重写历史之后，可能旧的和新的历史记录都存在，导致仓库体积反而变大[6]。 git-filter-repo[7] 特点： git filter-branch 的官方替代，官方推荐使用该工具来代替原生 git-filter-branch 命令。 速度快，功能多，使用灵活。 使用示例： 123$ git filter-repo --path bigfile.zip --path big/files/dir/ --invert-paths$ git push origin --tags --force$ git push origin --all --force 问题： 需要删除的文件可能不在当前工作区，而是在历史提交中，用户无法直接提供文件名、文件 ID 进行删除； 依赖 Python 环境。 BFG Repo-Cleaner[8] 特点： 速度快，使用比较简单。 使用示例： 123456$ java -jar bfg.jar --strip-blobs-bigger-than 100M my-big-repo.git$ cd my-big-repo.git$ git reflog expire --expire=now --all$ git gc --prune=now --aggressive$ git push origin --tags --force$ git push origin --all --force 问题： 不会处理最新的 commit(HEAD commit)； 会在所有被处理的 commit 信息中加入额外的信息。如：Former-commit-id: xxxxx，特别是如果多次运行该命令，则会在这些 commit 中加入多条额外信息，这会污染commit信息； 处理之后会在 HEAD commit 中加入很多额外信息； 对松散对象没有做处理；如果松散对象是要删除的大文件，则不会成功； 需要额外手动进行 GC 操作； 依赖 Java 环境。 git-siezer[9] 特点： 对 Git 仓库中的数据指标进行详细的统计。 使用实例： 1$ git sizer --threshold=0 问题： 只是对仓库的数据信息做概括统计。如：总的 commit 数量，总的文件(blob)数量，最大的单个文件等，不能告诉用户最大的 N 个文件，不能进行文件删除、历史重写。 git-repo-clean 设计目标： 通过对以上工具的特点、问题进行总结，我们试图开发出一款工具，解决以下问题： 纯命令行方式对有些用户不太友好，并且使用说明都是英文，阅读英文使用文档比较困难 没有自动对仓库进行备份，由于可能误操作，丢失仓库数据 对仓库历史文件不太了解，无法准确知道需要删除哪些文件 删除过程太慢。 这款工具就是：git-repo-clean[10]。 总的来说，git-repo-clean 具备以下优势： 使用简单。支持交互模式，用户操作起来比单纯的命令行方式更简单。 支持扫描模式。当对历史提交文件不太了解时，可以选择先扫描仓库，只需提供文件类型、大小、数量即可扫描出目标历史文件，再进行删除(交互模式下，也会使用扫描模式)，弥补了 git-filter-branch的缺点。 支持直接指定文件进行删除。 支持删除指定目录下的所有文件(包括目录本身)，及其提交记录。 速度快。从 v1.2.0 开始，git-repo-clean的速度可以达到与 git-filter-repo 同级别速度。 无其它依赖。源码使用 Golang 实现，通过交叉编译，最终可执行程序可在多平台兼容，不需要依赖特定的语言环境。 本地化。有中文文档，软件使用界面支持本地化。 git-repo-clean 技术原理： 一般来说，我们要创建一个 Git 仓库，需要以下操作： 123$ git init mini-repo &amp;&amp; cd mini-repo$ touch README &amp;&amp; echo &quot;first file in repo&quot; &gt; README$ git add README &amp;&amp; git commit -m &quot;init commit&quot; Git 内部提供了两个命令: git-fast-export, git-fast-import， 他们分别的作用是将 Git 仓库数据(.git/objects)导出为特定格式的 元数据，然后流式读取这种特定格式的元数据，于是就成一个完整的 Git 仓库。 任何符合格式的完整的元数据，输入给 git-fast-import 都能创建一个 Git 仓库。 我们先来看下一组最小完整的 Git 元数据： 1234567891011121314blob # blob类型，即文件mark :1 # 标号1data 32 # 文件大小FILE: this is the file content. # 文件内容reset refs/heads/master # 分支commit refs/heads/master # commit指向的分支mark :2 # 标号2author Li Linchao &lt;lilinchao@oschina.cn&gt; 1633749750 +0800 # commit作者committer Li Linchao &lt;lilinchao@oschina.cn&gt; 1633749750 +0800 # commit提交者data 65 # commit信息大小COMMIT: this is the commit message. The file name will be README # commit信息M 100644 :1 README # commit修改的文件，相当于tree,即文件名# M表示修改modify(新增也是修改)，100644表示文件类型，1表示指向标号为1的blob，README表示blob标号为1的文件名 通过这组元数据，使用 git fast-import 命令，就能创建出一个完整的仓库，里面包含: 一个文件，文件大小是 32 Bytes, 内容是：FILE: this is the file content. 一个分支，分支名为 master 一个 commit 提交，表示对 README 文件的修改。提交信息是：COMMIT: this is the commit message. The file name will be README 口说无凭，我们来看下这组元数据实际怎么生成一个完整 Git 仓库的。 首先需要在一个空的 Git 仓库中进行操作，然后将上述元数据输入到 git fast-import 中。 假设上述元数据存放在文件 meatadata 中。 接下来，具体操作如下： 123$ git init fake-repo &amp;&amp; cd fake-repo$ git fast-import --force --quiet --date-format=raw-permissive &lt; ../metadata$ git reset --hard HEAD # 清除缓存区，和工作区，回到最新的commit上 成功之后，刚创建的新仓库 fake-repo 下就有了一个 README 文件，一个 commit 提交，一个 master 分支： README 文件信息和 commit 信息都是根据元数据 metadata 中的定义而来，我们可以任意修改。 可以说，Git 元数据是对 Git 仓库中的底层数据(blob, tree, commit, tag)进行结构化表示。 那么，如果我们想对一个现存的 Git 仓库进行有目的修改，可以先获得该仓库的元数据，然后进行相应操作。 1如何获得一个 Git 仓库的元数据呢？ 那就是前面提到的 git fast-export 命令。 git fast-export 命令可以接受很多参数，比如： --show-original-ids 用于在输出中加入每个数据类型的原始 hash ID, 这个对于重写 commit 历史，或者通过 ID 裁剪 blob 有帮助。 --reencode=(yes|no|abort) 用于处理 commit 信息中的编码问题， yes 表示将 commit message 重新编码为 UTF-8。 --no-data 会在输出中省略 blob 类型数据。 具体应该使用什么参数，可以根据修改的目的来调整。 例如， 使用--show-original-ids, --reencode, --use-done-feature, --all 选项时的输出如下： 到目前为止，我们已经知道如何获取仓库元数据，也知道怎么根据元数据生成一个新的仓库，那么如果我们想要对仓库进行修改，只需要在这个过程中进行元数据过滤即可。 所以 git-clean-repo 的大致流程如下： 1234567891011121314151617git-fast-export | | output stream V ---&gt; parser(blob, tree, commit...) | | V ----&gt; filter(blob size, blob id, blob diectory...) | | input stream V ----&gt; git-fast-import | | V new repo 要解析的元数据中存在不同的数据类型， 它们的格式为： blob 12345blobmark [mark id]data [file size][file content]# LF换行 其中，mark id 的格式为 :n, 比如：:2 reset 12reset [ref name]from [parent id] (optional) commit 12345678910commit [ref name]mark [mark id]author [author info]committer [committer info]data [commit message info size][commit message info]merge [merge parent]from [from parent]filechanges# LF 其中，filechanges 格式如下： 12345678910111213[type] [file-mode] [file-id] [file-path]# type:# M: modify# A: add# C: copy# D: delete# file mode:# 100644 or 644: normal, but non executable file# 100755 or 755: normal, but executable file# 120000: symlink# 160000: gitlink# 040000: *subdirectory tag 12345678tag [tag name]mark [mark id]from [parent id]original-oid [original object id]tagger [tagger info]data [tag message info size][tag message]# LF git-fast-export 的输出中，mark 标号(mark ID)比较关键，它是每种数据的原始顺序，以及引用时的索引号。 每当从 git-fast-export 输出流中解析到一种完整的数据，需要对数据中我们关心的字段进行检查。 比如，我们要根据文件大小来过滤掉仓库中的大文件，在解析到 blob 数据类型时，当获取到 blob size 信息时，可以与我们的预期大小进行对比，如果超过预期大小，则可以把这个 blob 标记为可删除状态，整条 blob 数据都不会输入到 git-fast-import 中，这样就做到了文件删除， 同时记住这个 blob 的 mark ID, 后续继续流式输出时，只要涉及到引用该 mark ID 的 commit，需要将其中的 filechanges 进行修改。如果一个 commit 的 filechanges 删减到为零，则整条 commit 需要丢掉，这样就实现了与删除文件相关的 commit的更新。 我们用一组示意图进行说明： 上图表示一个简单仓库中元数据的组织方式，为了方便展示，省略了tag、引用等数据结构，只突出文件及其提交。 图中有4个文件：Blob-A, Blob-B, Blob-C, Blob-D。 产生了3个提交：Commit-A, Commit-B, Commit-C。 Commit-A提交涉及文件Blob-A, Blob-B, Commit-B提交涉及文件Blob-C, Commit-C提交涉及文件Blob-D。 使用git-fast-export导出仓库的元数据时，是按数据的先后顺序流式输出的，这个顺序即是mark ID的顺序。所以，本示例图中的数据顺序就是： 现在的目标是要删除文件Blob-C，以及它涉及到的提交。 删除的方式可以从文件的几个维度入手： 文件的名称 文件的ID, 即图中的 original-oid 文件的大小，即图中的 data size 无论哪种方式，目的是要先筛选出目标文件，然后进行标记。 所谓标记，可以简单的认为是将它的mark ID从原有的序号系统中剔除，即标记为0。 当blob的mark ID标记为0之后，后续解析到的commit时，会检查其中的filechanges，标记为0的filechange会被移除，如果最终的filechanges数量为0，说明该条commit所涉及到的所以修改文件都已经被删除，则整条commit也应该被删除。 在Blob-C, Commit-B标记为删除之后，后续所有数据的mark ID需要相应的改变, 以便保持一致。 如Commit-C 的mark ID变为5， parent commit(from)指向3，filechanges指向4。 这样就完成了删除文件Blob-C，以及其涉及到的Commit-C。 对于多文件，或者多分支删除，因为整个过程的数据是流式输出，所有的数据都按出场顺序有自己的唯一编号，所以处理起来是一样的。 以上就是 git-repo-clean的内部原理。 使用建议： 不管是哪种重写历史的工具，都是对仓库进行破坏性操作，有些事项需要特别注意。 事项 1：备份你的原始仓库 git repo-clean 在交互模式下，会询问用户是否进行备份，如果选择是，则会自动帮用户进行仓库备份。 事项 2：重写历史会改变 commit 的 ID 值，可能会影响现存 PR，所以建议先关掉或者合并现存 PR。 事项 3：在本地仓库重写历史并强制推送到远程仓库之后，应该告知所有使用该仓库进行协同开发的人，需要同步远程仓库，避免再将本地旧的历史提交到远程。 参考远程仓库更改后如何更新本地仓库[11][12] 后续： 在v1.3.0中我们已经实现将大文件转换为 Git LFS 文件的功能。 引用参考 [1]. https://gitee.com/cactusinhand/all-about-git/blob/master/doc/large-git-repos-zh.md [2]. https://git-scm.com/docs/gitignore [3]. https://gitee.com/help/articles/4235 [4]. https://git-scm.com/docs/git-filter-branch [5]. https://git-scm.com/docs/git-filter-branch#PERFORMANCE [6]. https://git-scm.com/docs/git-filter-branch#SAFETY [7]. https://github.com/newren/git-filter-repo [8]. https://github.com/rtyley/bfg-repo-cleaner [9]. https://github.com/github/git-sizer [10]. 开源中国/git-repo-clean [11]. https://gitee.com/oschina/git-repo-clean/blob/main/docs/repo-update.md [12]. https://htmlpreview.github.io/?https://raw.githubusercontent.com/newren/git-filter-repo/docs/html/git-rebase.html","tags":["Git","Tools"],"categories":["Git"]},{"title":"Git 炸弹","path":"/posts/c5ceb3cc.html","content":"起源 Git 炸弹因 XML 炸弹(AKA “billion laughs”)而得名，所以要理解 Git 炸弹，我们不妨先从 XML 炸弹说起。 下面是一段 XML 文件示例： 12345678910111213&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE lolz [&lt;!ENTITY lol&quot;laugh out loud&quot;&gt;&lt;!ENTITY lol2&quot;&amp;lol;&amp;lol;&amp;lol;&amp;lol;&amp;lol;&amp;lol;&amp;lol;&amp;lol;&amp;lol;&amp;lol;&quot;&gt;&lt;!ENTITY lol3&quot;&amp;lol2;&amp;lol2;&amp;lol2;&amp;lol2;&amp;lol2;&amp;lol2;&amp;lol2;&amp;lol2;&amp;lol2;&amp;lol2;&quot;&gt;&lt;!ENTITY lol4&quot;&amp;lol3;&amp;lol3;&amp;lol3;&amp;lol3;&amp;lol3;&amp;lol3;&amp;lol3;&amp;lol3;&amp;lol3;&amp;lol3;&quot;&gt;&lt;!ENTITY lol5&quot;&amp;lol4;&amp;lol4;&amp;lol4;&amp;lol4;&amp;lol4;&amp;lol4;&amp;lol4;&amp;lol4;&amp;lol4;&amp;lol4;&quot;&gt;&lt;!ENTITY lol6&quot;&amp;lol5;&amp;lol5;&amp;lol5;&amp;lol5;&amp;lol5;&amp;lol5;&amp;lol5;&amp;lol5;&amp;lol5;&amp;lol5;&quot;&gt;&lt;!ENTITY lol7&quot;&amp;lol6;&amp;lol6;&amp;lol6;&amp;lol6;&amp;lol6;&amp;lol6;&amp;lol6;&amp;lol6;&amp;lol6;&amp;lol6;&quot;&gt;&lt;!ENTITY lol8&quot;&amp;lol7;&amp;lol7;&amp;lol7;&amp;lol7;&amp;lol7;&amp;lol7;&amp;lol7;&amp;lol7;&amp;lol7;&amp;lol7;&quot;&gt;&lt;!ENTITY lol9&quot;&amp;lol8;&amp;lol8;&amp;lol8;&amp;lol8;&amp;lol8;&amp;lol8;&amp;lol8;&amp;lol8;&amp;lol8;&amp;lol8;&quot;&gt;]&gt;&lt;lolz&gt;&amp;lol9;&lt;/lolz&gt; 从 ENTITY 字段看起，每行 ENTITY 代表一个 XML 实体(entity)元素，一共10个实体元素，除了第一个实体 lol 定义了字符串&quot;laugh out loud&quot;(AKA lol)外, 其余实体都是实体引用，它们每个都引用自上一个实体，且重复10次。 此 XML 文件的文档内容部分仅包含对实体lol9的一个实例的引用。但是，当它被 DOM 或 SAX 解析器解析时，遇到lol9时，它会扩展为 10 个lol8，而每个lol8会扩展为10 个lol7，依此类推。到将所有内容扩展为文本lol时，字符串&quot;laugh out loud&quot;的数量已达100,000,000。如果再增加一个类似结构的实体，或者第一个实体lol被定义为10个&quot;laugh out loud&quot;字符串的话，那么将有10亿个&quot;laugh out loud&quot;，即十亿大笑。 这段文本看似内容不多，占用内存不大，但是在解析过程中内容被指数级展开，会消耗大量内存资源，所以有人利用这个原理进行DOS攻击，使被攻击的机器的内存迅速耗尽，从而停止服务。 以上这种 XML 攻击，被称作 XML 炸弹。 Git 炸弹的原理大致也跟XML炸弹类似，它利用了 Git 的某种特性，使得重复的文本内容深度嵌套。所以接下来再来看一下 Git 炸弹的原理。 Git 炸弹原理 我们都知道 Git 的基本数据结构有commit,tag, tree, blob, blob 只存储文件内容，tree 存储文件名称，文件目录结构， commit 与 tag 类似于一种引用(reference),指向 tree。 每中数据都有自己的hash ID, 所以对于blob来说，只要其中的内容是一样的，那么其 ID 就是一样的，不管其内容的文件名，文件路径是否相同。换句话说，Git消除了blob的重复，允许不同的文件(文件名，文件路径不同)使用相同的blob，目的是减少文件内容的重复。对于tree也是类似。 所以有人就利用这个特性制作了一个 Git 仓库, 其结构类似： 之后，只要运行包含树的遍历操作的 Git 命令，如git status, git checkout 等命令，Git 会先在内存中构造出该仓库的树结构，在这种特殊的仓库中，这个过程会消耗大量内存，因此只要这个仓库的树嵌套足够深，内存就会马上被消耗完，相关进程会被终止。 与XML炸弹类似，只要这种嵌套结构达到10层，或者底层的 blob 有10个，则整个过程展开会有 10 亿条 tree(路径)。 制作 Git炸弹第一次公开讨论是在 2017 年，Kate 在自己的博客[2]中讨论了制作 Git 炸弹的原理以及制作方法，制作程序是用 Python 写的，见： https://kate.io/blog/making-your-own-exploding-git-repos 如何防止 经过 Github 以及漏洞平台 Hackerone 同意后，Kate 公开了自己在 Github 上自己的 git-bomb仓库[3]，并且在自己的博客中公开讨论了 Git 炸弹的相关信息，之后马上引起了 Git 上游社区的关注，并且马上讨论了可能的修复方案: [4] Git上游社区，最终补丁: [5] Git 官方的修复是将遍历树的过程变得更快，使得对 Git 炸弹仓库做任何操作不至于等待很久。其commit message写到： 12345678910111213141516171819202122You can see this in a pathological case where a commit addsa very large number of entries, and we limit based on abroad pathspec. E.g.: perl -e &#x27; chomp(my $blob = `git hash-object -w --stdin &lt;/dev/null`); for my $a (1..1000) &#123; for my $b (1..1000) &#123; print &quot;100644 $blob\\t$a/$b &quot;; &#125; &#125; &#x27; | git update-index --index-info git commit -qm add git rev-list HEAD -- .This case takes about 100ms now, but after this patch onlyneeds 6ms. That&#x27;s not a huge improvement, but it&#x27;s easy toget and it protects us against even more pathological cases(e.g., going from 1 million to 10 million files would taketen times as long with the current code, but not increase atall after this patch). 这个修复并没有解决处理这种仓库导致内存消耗过大问题，只对处理过程的消耗时间做了一次优化。 相关 CVE CVE-2017-15298 参考链接 microsoft: xml-denial-of-service-attacks-and-defenses kate’s blog kate: original git-bomb repo on Github git upstream discussion git upstream fix","tags":["Git-bomb","Xml"],"categories":["Git"]},{"title":"Git 内部原理","path":"/posts/4fad1e06.html","content":"本文将深入分析 Git 底层的核心数据结构，如 blob, tree, commit, tag 。通过理解底层数据结构，我们就会更容易理解和掌握相关 Git 命令操作。 普通Git仓库分为： 工作区(workspace/working copy) 暂存区(stage/index) 仓库区(local repository/objects database) 裸仓就是不包含工作区的仓库，一般服务端的仓库(即远程库)就是裸仓。 仓库名结尾一般使用 .git为了与正常仓库区分，但不是强制。 创建裸仓的方式有两种： 12$ git init --bare &lt;bare-repo&gt;$ git clone --bare source-repo &lt;bare-repo&gt; 我们新建一个空的裸仓, 命名为 remote.git: 1$ git init --bare remote.git 然后再创建两个副本，后续的实验就是在repo_a, repo_b中进行： 12$ git clone remote.git repo_a$ git clone remote.git repo_b 进入刚克隆的一个仓库 repo_a 中，只有 .git 目录，.git 目录中的所有文件，即是裸仓中的所有文件，但作为一个正常仓库，目前它工作区还是为空。好在我们可以手动创建一些内容。 认识blob object git hash-object： 将数据保存到对象数据库中 123$ echo -n &#x27;Hello, Git&#x27; &gt; README$ git hash-object -w README6fe402b35d6e80a187adc393f36ce10e4fdd259f 选项-n 为了避免echo在输出字符串时自动添加换行符。 选项 -w表示写入，如果不加这个选项，则仅是计算文件的hash值，不会保存。 这里将内容 Hello, Git 写入文件README，再对该文件运行了 git hash-objects 命令，并返回了一串值。这串值会以某种形式下保存下来。 用 git count-objects 命令得知，此时仓库已经有了第一个对象： 12$ git count-objects$ 1 objects, 4 kilobytes 可以通过 tree 命令查看下 .git/objects 目录： 12345678$ tree .git/objects.git/objects├── 6f│ └── e402b35d6e80a187adc393f36ce10e4fdd259f├── info└── pack3 directories, 1 file 我们把 .git/objects 目录称作对象数据库(object database)，新增的对象都会存到这个目录下。 里面还是熟悉的那串数字，我们对Git的认识就从这一串数字开始。 git cat-file ： 剖析git数据对象 通过 git cat-file 命令查看新生成的对象： 12$ git cat-file -p 6fe402b35d6e80a187adc393f36ce10e4fdd259fHello, Git 顺便还可以看一下对象的类型： 12$git cat-file -t 6fe402b35d6e80a187adc393f36ce10e4fdd259fblob 这里，我们认识到了git对象中的第一种类型blob object, 称之为数据对象。 我们创建了一个文件，内容是 Hello, Git, 通过 git hash-object命令将内容写入到 .git/objects目录中，并且返回指向该数据对象的唯一的键，它是一个40-bit的hash值，通过这串值即可寻找出它对应的文件的内容，因此blob数据对象可表示如下： 这也是Git的内容可寻址的文件系统(Content-Addressable Filesystem)的含义。 同时我们也知道了Git会将这40-bit的hash值的前2位作为 .git/objects目录下的子目录，后38位作为子目录下的一个文件的文件名。 通过 file命令我们可以知道这是一个zlib压缩文件： 12$ file .git/objects/6f/e402b35d6e80a187adc393f36ce10e4fdd259f.git/objects/6f/e402b35d6e80a187adc393f36ce10e4fdd259f: zlib compressed data 既然是被压缩过的，那么里面的内容就是不可读的。 为了查看里面的内容，先安装一个解压缩工具： 12$ apt-get update$ apt-get install pigz 然后运行： 12$ pigz -d &lt; .git/objects/6f/e402b35d6e80a187adc393f36ce10e4fdd259fblob 10Hello, Git -d 表示解压 可以看到在进行hash时，git内部是按照特定格式进行的: 切到 repo_b，我们可以手动验证这个过程： 12$ echo -ne &#x27;blob 10\\0Hello, Git&#x27; | sha1sum6fe402b35d6e80a187adc393f36ce10e4fdd259f - 选项-e 为了让echo能够识别反斜杠转义符（即字符串中的’\\0’) 再次使用 git hash-objects 验证这条数据： 12$ echo -n &#x27;Hello, Git&#x27; | git hash-object --stdin6fe402b35d6e80a187adc393f36ce10e4fdd259f 结果是一致的，说明 git hash-objects 在生成hash时，是严格按照特定格式进行的。 此时并没有创建 .git/objects/6f 目录，因为没有加 -w 选项，我们可以手动完成。 我们知道Git会对数据使用 zlib 的 deflate 算法进行压缩，我们也手动验证一下： 创建一个目录和文件： 12$ mkdir .git/objects/6f$ touch .git/objects/6f/e402b35d6e80a187adc393f36ce10e4fdd259f 接着，使用 pigz 工具压缩数据，存放到 e402b35d6e80a187adc393f36ce10e4fdd259f 文件中： 1$ echo -ne &#x27;blob 10\\0Hello, Git&#x27; | pigz -cz &gt; .git/objects/6f/e402b35d6e80a187adc393f36ce10e4fdd259f -c 表示输出，-z 表示采用zlib的deflate算法 此时我们才可以用 git cat-file 查看一下里面的内容： 12$ git cat-file -p 6fe402b35d6e80a187adc393f36ce10e4fdd259fHello, Git 同样我们可以 解压，看看压缩文件里面的内容： 12$ pigz -d &lt; .git/objects/6f/e402b35d6e80a187adc393f36ce10e4fdd259fblob 10Hello, Git 结果是与前面一致的。 回到 repo_a 仓库继续实验其它内容。 再对README文件进行修改： 12345678# 改写文件$ echo -n &quot;Hello, Gitee&quot; &gt; README# 写入对象数据库$ git hash-object -w README216ef921a90b782fed1ca37223c3141ed7d5de32# 查看内容$ git cat-file -p 216ef921a90b782fed1ca37223c3141ed7d5de32Hello, Gitee 再次查看一下 .git/object目录： 12345678910$ tree .git/objects.git/objects├── 21│ └── 6ef921a90b782fed1ca37223c3141ed7d5de32├── 6f│ └── e402b35d6e80a187adc393f36ce10e4fdd259f├── info└── pack4 directories, 2 files 里面有两个 Git 对象了，它们分别代表 README 的两个版本。 我们写入了 blob 对象，通过 git status 查看工作区状态，可以看到 README 仍是 Untracked files 状态，也就是暂存区还是空的，此时 .git/ 目录中还不存在 index 文件。 我们可以先更新一下暂存区，需要用到新的命令： git update-index: 将工作区的文件内容更新到 index 区 1$ git update-index --add --cacheinfo 100644 6fe402b35d6e80a187adc393f36ce10e4fdd259f README –add 表示加到Index中 –cacheinfo表示是从git数据库.git/object中添加文件 100644表示普通文件 再次 git status 查看状态，就不一样了： 12345678910111213$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: README #version 1 index区Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: README #version 2 工作区 同时我们也可以看到生成了文件 .git/index。 以上过程相当于 git add REAME 所以 git add file 就是将工作区的文件内容更新到暂存区。 认识tree object 前面认识的 blob 对象只是文件的内容本身，以及它的hash值，并没有涉及到文件名，要保存文件名需要 tree 对象。 git write-tree: 从当前 index 区创建树对象 12$ git write-tree16ab25f42fdb4563f1acb0ff8b978493bfd2bc1c # tree 1 又生成了一个 hash 值。查看一下： 12345$ git cat-file -t 16ab25f42fdb4563f1acb0ff8b978493bfd2bc1ctree$ git cat-file -p 16ab25f42fdb4563f1acb0ff8b978493bfd2bc1c100644 blob 6fe402b35d6e80a187adc393f36ce10e4fdd259f README 内容与之前暂存区的内容一致，说明确实是从暂存区到了数据库。 这样我们也就认识到了 git 对象中的第二种类型 tree object，即树对象。 tree 对象不仅可以保存文件名，还可以保存多个文件的内容及其唯一键，而且它还允许嵌套子树，这相当于文件目录。 我们先再建一棵树： 1234567891011121314151617181920$ echo &#x27;1.0&#x27; &gt; VERSION$ git update-index --add VERSION$ git update-index --add README # version 2$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: README new file: VERSION $ git write-tree33ad99f76f295411d5c198cb58c5c95e5d0b3c91 # tree 2$ git cat-file -p 33ad99f76f295411d5c198cb58c5c95e5d0b3c91100644 blob 216ef921a90b782fed1ca37223c3141ed7d5de32 README100644 blob d3827e75a5cadb9fe4a27e1cb9b6d192e7323120 VERSION 这个目录树包含两个文件对象。 其实还可以包含子树，我们可以利用 git read-tree 把第一棵树整个读入暂存区，然后再写入Git 的数据库。 git read-tree: 将树信息读到暂存区 12345# 第一棵树读到index区，并放到bak下面$ git read-tree --prefix=bak 16ab25f42fdb4563f1acb0ff8b978493bfd2bc1c# 将当前整个状态写入新的树，放回数据库$ git write-tree77e9ad8de018dab58d76e0667507378b3cfe4808 # tree 3 但是此时并没有创建正真的 bak 目录，至少在工作区是没有的(ls查看不到)，它目前只存在于暂存区中 123456789101112131415$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: README new file: VERSION new file: bak/READMEChanges not staged for commit: (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) deleted: bak/README 此时只需要使用 git checkout 命令将它从暂存区恢复到工作区就行： 12345$ git checkout -- bak/README$ git status# 此时可以观察到确实有这个目录了$ lsREADME VERSION bak 同时别忘了 git cat-file 查看新树： 1234$ git cat-file -p 77e9ad8de018dab58d76e0667507378b3cfe4808100644 blob 216ef921a90b782fed1ca37223c3141ed7d5de32 README100644 blob d3827e75a5cadb9fe4a27e1cb9b6d192e7323120 VERSION040000 tree 16ab25f42fdb4563f1acb0ff8b978493bfd2bc1c bak 100644表示普通文件，040000 表示目录 用一张图表示： 认识commit object git commit-tree： 创建 commit 对象 目前我们有三棵树：16ab2， 33ad9， 77e9a 现在可以根据树来创建 commit： 123456789$ echo &#x27;first commit&#x27; | git commit-tree 16ab23aa1317953001375c744a8a12f59a37cc1640fdb$ git log 3aa13commit 3aa1317953001375c744a8a12f59a37cc1640fdbAuthor: Li Linchao &lt;lilinchao@oschina.cn&gt;Date: Mon Aug 16 16:16:31 2021 +0800 first commit(END) 12345678$ git cat-file -t 3aa1317953001375c744a8a12f59a37cc1640fdbcommit$ git cat-file -p 3aa1317953001375c744a8a12f59a37cc1640fdbtree 16ab25f42fdb4563f1acb0ff8b978493bfd2bc1cauthor Li Linchao &lt;lilinchao@oschina.cn&gt; 1629101791 +0800committer Li Linchao &lt;lilinchao@oschina.cn&gt; 1629101791 +0800first commit 这个过程相当于 git commit -m &quot;message&quot;。 以上就创建了 git 对象中的第三种类型 commit object，即提交对象 其它的 commit 时按照 tree 生成的顺序来： 1234567891011121314151617181920212223242526272829303132333435363738$ echo &#x27;second commit&#x27; | git commit-tree 33ad9 -p 3aa132aa80fc99a89a808fc0342972c5a3514d41fa5f7$ git log 2aa8commit 2aa80fc99a89a808fc0342972c5a3514d41fa5f7Author: Li Linchao &lt;lilinchao@oschina.cn&gt;Date: Mon Aug 16 16:21:42 2021 +0800 second commitcommit 3aa1317953001375c744a8a12f59a37cc1640fdbAuthor: Li Linchao &lt;lilinchao@oschina.cn&gt;Date: Mon Aug 16 16:16:31 2021 +0800 first commit(END)$ echo &#x27;third commit&#x27; | git commit-tree 77e9a -p 2aa80bdc5642cd9e8a62767710d1d9761b056f91f094c$ git log bdc56commit bdc5642cd9e8a62767710d1d9761b056f91f094cAuthor: Li Linchao &lt;lilinchao@oschina.cn&gt;Date: Mon Aug 16 16:23:00 2021 +0800 third commitcommit 2aa80fc99a89a808fc0342972c5a3514d41fa5f7Author: Li Linchao &lt;lilinchao@oschina.cn&gt;Date: Mon Aug 16 16:21:42 2021 +0800 second commitcommit 3aa1317953001375c744a8a12f59a37cc1640fdbAuthor: Li Linchao &lt;lilinchao@oschina.cn&gt;Date: Mon Aug 16 16:16:31 2021 +0800 first commit(END) 不管是数据对象(blob object), 树对象(tree object), 提交对象(commit object)，所有的对象都会放到对象数据库中： 123456789101112131415161718192021222324$ tree .git/objects.git/objects├── 16│ └── ab25f42fdb4563f1acb0ff8b978493bfd2bc1c├── 21│ └── 6ef921a90b782fed1ca37223c3141ed7d5de32├── 2a│ └── a80fc99a89a808fc0342972c5a3514d41fa5f7├── 33│ └── ad99f76f295411d5c198cb58c5c95e5d0b3c91├── 3a│ └── a1317953001375c744a8a12f59a37cc1640fdb├── 6f│ └── e402b35d6e80a187adc393f36ce10e4fdd259f├── 77│ └── e9ad8de018dab58d76e0667507378b3cfe4808├── bd│ └── c5642cd9e8a62767710d1d9761b056f91f094c├── d3│ └── 827e75a5cadb9fe4a27e1cb9b6d192e7323120├── info└── pack11 directories, 9 files 创建成功 commit 对象后，很快我们就会发现一个问题： 12$ git logfatal: your current branch &#x27;master&#x27; does not have any commits yet 前面查看 log 时指定了 commit ID 才有结果，但是如果不指定 commit，系统就提示当前分支没有 commit，这是怎么回事？我们平时都是没指定也能正常使用对吧。 原因是还有些工作没有完成，这就涉及到Git引用(Git Reference)。 在 local_a 仓库中，目前我们还没有创建任何引用，所以 .git/refs 下面还是空的： 12345$ find .git/refs.git/refs.git/refs/tags.git/refs/heads$ find .git/refs -type f 我们还是继续手动创建。 首先我们需要一个指向当前分支（默认master）最新提交(bdc56)的引用： 1$ echo bdc5642cd9e8a62767710d1d9761b056f91f094c &gt; .git/refs/heads/master 此时，再次运行 git log，不需要指定 commit ID 就能看到全部提交历史了。 实际上 git 有专门的命令完成引用设置：git-update-ref 1$ git update-ref refs/heads/master bdc5642cd9e8a62767710d1d9761b056f91f094c 基于引用，于是就有了分支的实现。实际上每个分支都有一个 head 指针，指向该分支的最新提交。 假设我们在第二次提交(2aa80fc99a89a808fc0342972c5a3514d41fa5f7)上切出一个分支，实际上就是加一个引用名，如 dev: 1$ git update-ref refs/heads/dev 2aa80 git log 可以看到第二次提交上有个 dev 的标签，运行 git branch 也可以看到有 dev 分支。 通过 git log可以看到有个特殊的指针HEAD，它是指向引用的引用，它永远指向当前分支。 当前分支在 master 分支上，所以HEAD指向 master，当使用 git checkout dev 后可以看到HEAD指向 dev, 表示当前切换到了 dev 分支。 HEAD是一种符号引用(symbolic reference) git 有个专门的命令用来读取，修改，删除符号引用：git symbolic-ref 12$ git symbolic-ref HEADrefs/heads/master 表示当前分支是master 1$ git symbolic-ref HEAD refs/heads/dev 改变HEAD的指向, 也意味着切换分支 认识tag object 其实还有一种比较少用到的 Git 数据对象是 tag object，它和 commit 对象有点类似，创建方式是: 1$ git tag -a tag-name -m &quot;tag message&quot; 比如我们创建一个 v1.0 的 tag: 12345678910111213141516171819202122232425$ git tag -a v1.0 -m &quot;version 1.0&quot;$ cat .git/refs/tags/v1.005f749dc5667010dbe07ee181b3607143b84b14f$ git cat-file -t 05f749dc5667010dbe07ee181b3607143b84b14ftag$ git cat-file -p 05f749dc5667010dbe07ee181b3607143b84b14fobject bdc5642cd9e8a62767710d1d9761b056f91f094ctype committag v1.0tagger Li Linchao &lt;lilinchao@oschina.cn&gt; 1629103432 +0800version 1.0# 或者$ git cat-file -t v1.0tag$ git cat-file -p v1.0object bdc5642cd9e8a62767710d1d9761b056f91f094ctype committag v1.0tagger Li Linchao &lt;lilinchao@oschina.cn&gt; 1629103432 +0800version 1.0 git tag 的 hash 值在 .git/refs/tags/v1.0 文件里面。v1.0 是文件名，也是 tag 名称，文件内容是 tag 的 hash 值，它们一一对应，v1.0 就是 db1cc3710e8b284f44286400b61974a8f1e633d4 的指针。 我们可以借助 git-draw 工具生成一张图来说明此时的仓库各个数据之间的关系： 1$ ../git-draw -i --hide-index --hide-legend --hide-reflogs --hide-refs --image-filename output.png 工具地址: https://github.com/sensorflo/git-draw 或者手动绘制各种数据的关系，如下： http://assets.processon.com/chart_image/60a12b2fe0b34d34ca5ef5e7.png 参考 Git 内部原理 - Git 对象 Git 内部原理 - Git 引用 认识Git对象 认识Git引用","tags":["Git-inside"],"categories":["Git"]},{"title":"关于","path":"/about/index.html","content":"@Cactusinhand Languages: C/C++、Golang、Python、Rust Favourite Thing: Movies, jogging, climbing"},{"title":"一种Git仓库瘦身工具","path":"/wiki/git-tools/index.html","content":"安装： 二进制包安装： 见下载链接：https://gitee.com/oschina/git-repo-clean/releases/ 源码编译安装： 123456789$ git clone https://gitee.com/oschina/git-repo-clean# 进入源码目录，编译$ cd git-repo-clean# 在bin/目录下即是编译后的程序包$ make# cp bin/git-repo-clean $(shell git --exec-path)$ make install 用法: git repo-clean [选项] ********************* 重要! ***************** *** 该历史重写过程是不可逆的破坏性的操作 *** *** 请在做任何操作之前先备份您的仓库数据 *** git repo-clean 是一款扫描Git仓库元数据，然后根据指定的文件类型以及大小来过滤出文件，并且从仓库中完全删除掉这些指定文件的工具，它将重写跟删除的文件相关的提交以及之后的提交的历史。 选项： 12345678910111213-v, --verbose 显示处理的详细过程-V, --version 显示 git-repo-clean 版本号-h, --help 显示使用信息-p, --path 指定Git仓库的路径, 默认是当前目录，即&#x27;.&#x27;-s, --scan 扫描Git仓库数据，默认是扫描所有分支中的数据-f, --file 直接指定仓库中的文件或目录，与&#x27;--scan&#x27;不兼容-b, --branch 设置需要删除文件的分支, 默认是从所有分支中删除文件-l, --limit 设置扫描文件阈值, 比如: &#x27;--limit=10m&#x27;-n, --number 设置显示扫描结果的数量-t, --type 设置扫描文件后缀名，即文件类型-i, --interactive 开启交互式操作-d, --delete 执行文件删除和历史重写过程-L, --lfs 将大文件转换为Git LFS指针文件 这些选项主要可以给用户提供两种使用方法：交互式、命令行式 交互式用法: 直接执行 git repo-clean 或 git repo-clean -i 进入交互式界面程序与用户通过问答的方式进行交互，使得用户在处理文件筛选、备份、删除、历史重写的整个过程变得更加简单。 命令行式用法： 用户可以在命令行中通过指定各种选项的参数，来实现功能，例如： 为了只扫描仓库中文件类型为 tar.gz，且大小超过 1G 的文件，执行： git repo-clean --scan --limit=1G --type=tar.gz 当需要删除指定文件时，需要加上 –delete 选项，执行： git repo-clean --scan --limit=1G --type=tar.gz --delete 如果相同文件存在多个分支中，或者发现前一次删除之后，相同的文件仍然存在，则可以使用 –branch 选项，从所有分支删除，执行： git repo-clean --scan --limit=1G --type=tar.gz --delete --branch=all 可以通过 –number 选项，控制扫描结果的数量，默认只扫描出前 3 个最大文件： git repo-clean --scan --limit=1G --type=tar.gz --delete --number=3 如果你想用 Git LFS 管理大文件，可以使用 –lfs 选项将大文件转换为 LFS 指针文件这个操作必须在扫描模式下进行，必须指定文件类型，即必须有 –scan, –type 参数此时 –number 参数无效： git repo-clean --scan --type=so --lfs --delete 在非扫描模式下，即不指定 –scan 参数，可以快速进行以下操作： 删除某些已知的文件，不必扫描仓库，使用 –file 选项直接指定文件： git repo-clean --file file1 --file file2 --delete 或者，批量删除某个目录下所有的文件： git repo-clean --file dir/ --delete 又或者，批量删除某种类型文件： git repo-clean --type=&quot;png&quot; --delete 再或者，批量删除超过某个大小的所有文件： git repo-clean --limit=10M --delete 更多情况见：官网"},{"title":"便笺","path":"/notes/index.html","content":"test notes"},{"title":"一种Hexo主题","path":"/wiki/stellar/index.html","content":"Stellar 一种 Hexo 主题 详情请看 官网"}]